{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b684e7e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13616,
     "status": "ok",
     "timestamp": 1749315438743,
     "user": {
      "displayName": "Aleksandra Hendrysiak",
      "userId": "02783590481816071264"
     },
     "user_tz": -120
    },
    "id": "6b684e7e",
    "outputId": "2986a8b3-588f-48eb-ae69-8ffde4b444de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d083af",
   "metadata": {},
   "source": [
    "### Select data and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012e36c2",
   "metadata": {
    "executionInfo": {
     "elapsed": 7077,
     "status": "aborted",
     "timestamp": 1749282048517,
     "user": {
      "displayName": "Aleksandra Hendrysiak",
      "userId": "02783590481816071264"
     },
     "user_tz": -120
    },
    "id": "012e36c2"
   },
   "outputs": [],
   "source": [
    "data_file = \"/content/drive/MyDrive/Master - A/test.csv\"\n",
    "data_file2 = \"//content/drive/MyDrive/Master - A/test2.csv\"\n",
    "df = pd.read_csv(data_file)\n",
    "df2 = pd.read_csv(data_file2)\n",
    "df = pd.concat([df, df2])\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "dataset_path = \"//content/drive/MyDrive/Master - A/Ostateczny\"\n",
    "img_size = (224, 224)\n",
    "x = os.listdir(dataset_path)\n",
    "selected_classes = x\n",
    "\n",
    "data = []\n",
    "X=[]\n",
    "for class_name in selected_classes:\n",
    "    class_path = os.path.join(dataset_path, class_name)\n",
    "    if not os.path.isdir(class_path):\n",
    "        continue\n",
    "    for img_file in os.listdir(class_path):\n",
    "        if not img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            continue\n",
    "\n",
    "        img_path = os.path.join(class_path, img_file)\n",
    "        filtered_row = df[df[\"image_path\"] == img_file]\n",
    "\n",
    "        if filtered_row.empty:\n",
    "            continue \n",
    "\n",
    "        try:\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            img = img.resize(img_size)\n",
    "            img_array = np.array(img) / 255.0  \n",
    "            X.append(img_array)\n",
    "\n",
    "            row_data = {\n",
    "                \"image_path\": img_file,\n",
    "                \"image_array\": img_array,\n",
    "                \"label\": class_name,\n",
    "                \"Substrate\": filtered_row[\"Substrate\"].values[0],\n",
    "                \"Habitat\": filtered_row[\"Habitat\"].values[0],\n",
    "                \"Latitude\": filtered_row[\"Latitude\"].values[0],\n",
    "                \"Longitude\": filtered_row[\"Longitude\"].values[0],\n",
    "                \"CoorUncert\": filtered_row[\"CoorUncert\"].values[0],\n",
    "                \"locality\": filtered_row[\"locality\"].values[0]\n",
    "            }\n",
    "\n",
    "            data.append(row_data)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Błąd przy {img_path}: {e}\")\n",
    "\n",
    "df_all = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "lSjjg4xxe9Xo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1749214148695,
     "user": {
      "displayName": "Aleksandra Hendrysiak",
      "userId": "02783590481816071264"
     },
     "user_tz": -120
    },
    "id": "lSjjg4xxe9Xo",
    "outputId": "f2d7cc63-f4e4-4372-89f9-abc423608da4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-b641cc0550e7>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features[\"Habitat_enc\"] = le_habitat.fit_transform(features[\"Habitat\"])\n",
      "<ipython-input-3-b641cc0550e7>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features[\"Substrate_enc\"] = le_substrate.fit_transform(features[\"Substrate\"])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8397, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = df_all[[\"Habitat\", \"Substrate\", \"Latitude\", \"Longitude\", \"CoorUncert\"]]\n",
    "\n",
    "le_habitat = LabelEncoder()\n",
    "le_substrate = LabelEncoder()\n",
    "\n",
    "features[\"Habitat_enc\"] = le_habitat.fit_transform(features[\"Habitat\"])\n",
    "features[\"Substrate_enc\"] = le_substrate.fit_transform(features[\"Substrate\"])\n",
    "X_meta = features[[\"Habitat_enc\", \"Substrate_enc\", \"Latitude\", \"Longitude\", \"CoorUncert\"]].values\n",
    "X_meta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "527c77bb",
   "metadata": {
    "executionInfo": {
     "elapsed": 6888,
     "status": "ok",
     "timestamp": 1749214155594,
     "user": {
      "displayName": "Aleksandra Hendrysiak",
      "userId": "02783590481816071264"
     },
     "user_tz": -120
    },
    "id": "527c77bb"
   },
   "outputs": [],
   "source": [
    "#X = df_all[\"image_array\"]\n",
    "# X = np.stack(df_all[\"image_array\"].values)\n",
    "y = df_all[\"label\"]\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "y_cat = to_categorical(y_encoded)\n",
    "y_all = np.array(y_cat)\n",
    "X = np.array(X)\n",
    "X_img_train, X_img_test, X_meta_train, X_meta_test, y_train_enc, y_test_enc = train_test_split(\n",
    "    X, X_meta, y_all, test_size=0.2, random_state=42, stratify=y_all\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7faffde",
   "metadata": {},
   "source": [
    "### Save pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hIY5CJ1w5ZUf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "executionInfo": {
     "elapsed": 396,
     "status": "error",
     "timestamp": 1749315439162,
     "user": {
      "displayName": "Aleksandra Hendrysiak",
      "userId": "02783590481816071264"
     },
     "user_tz": -120
    },
    "id": "hIY5CJ1w5ZUf",
    "outputId": "b6d4cf58-c1f2-4c41-cf06-4cccedb9ac07"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_img_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-925842d7321a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Dane, które chcesz zapisać\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m datasets = {\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;34m\"X_img_train\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_img_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;34m\"X_img_test\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_img_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;34m\"X_meta_train\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_meta_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_img_train' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "save_dir = \"/content/drive/MyDrive/Master - A/\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "datasets = {\n",
    "    \"X_img_train\": X_img_train,\n",
    "    \"X_img_test\": X_img_test,\n",
    "    \"X_meta_train\": X_meta_train,\n",
    "    \"X_meta_test\": X_meta_test,\n",
    "    \"y_train_enc\": y_train_enc,\n",
    "    \"y_test_enc\": y_test_enc,\n",
    "    \"label_encoder\": le,\n",
    "}\n",
    "\n",
    "for name, data in datasets.items():\n",
    "    file_path = os.path.join(save_dir, f\"{name}.pkl\")\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        pickle.dump(data, f)\n",
    "    print(f\"✔ Zapisano: {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "y4oDPEbESv_S",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1749214409669,
     "user": {
      "displayName": "Aleksandra Hendrysiak",
      "userId": "02783590481816071264"
     },
     "user_tz": -120
    },
    "id": "y4oDPEbESv_S"
   },
   "outputs": [],
   "source": [
    "del X, y, df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "yvOoMg1aS6Se",
   "metadata": {
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1749214409697,
     "user": {
      "displayName": "Aleksandra Hendrysiak",
      "userId": "02783590481816071264"
     },
     "user_tz": -120
    },
    "id": "yvOoMg1aS6Se"
   },
   "outputs": [],
   "source": [
    "del X_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e67960ea",
   "metadata": {
    "executionInfo": {
     "elapsed": 225,
     "status": "ok",
     "timestamp": 1749213296164,
     "user": {
      "displayName": "Aleksandra Hendrysiak",
      "userId": "02783590481816071264"
     },
     "user_tz": -120
    },
    "id": "e67960ea"
   },
   "outputs": [],
   "source": [
    "df_all = pd.read_csv(\"/content/drive/MyDrive/Master - A/3_fig/Dane.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cf90e1",
   "metadata": {},
   "source": [
    "### Save pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-JcrFxscAp5r",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 70729,
     "status": "ok",
     "timestamp": 1749315512379,
     "user": {
      "displayName": "Aleksandra Hendrysiak",
      "userId": "02783590481816071264"
     },
     "user_tz": -120
    },
    "id": "-JcrFxscAp5r",
    "outputId": "dcf5d96e-cc12-4959-ebd6-b628c685ea49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Wczytano: /content/drive/MyDrive/Master - A/X_img_train.pkl\n",
      "✔ Wczytano: /content/drive/MyDrive/Master - A/X_img_test.pkl\n",
      "✔ Wczytano: /content/drive/MyDrive/Master - A/X_meta_train.pkl\n",
      "✔ Wczytano: /content/drive/MyDrive/Master - A/X_meta_test.pkl\n",
      "✔ Wczytano: /content/drive/MyDrive/Master - A/y_train_enc.pkl\n",
      "✔ Wczytano: /content/drive/MyDrive/Master - A/y_test_enc.pkl\n",
      "✔ Wczytano: /content/drive/MyDrive/Master - A/label_encoder.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "load_dir = \"/content/drive/MyDrive/Master - A/\"\n",
    "\n",
    "dataset_names = [\n",
    "    \"X_img_train\",\n",
    "    \"X_img_test\",\n",
    "    \"X_meta_train\",\n",
    "    \"X_meta_test\",\n",
    "    \"y_train_enc\",\n",
    "    \"y_test_enc\",\n",
    "    \"label_encoder\"\n",
    "]\n",
    "\n",
    "loaded_data = {}\n",
    "\n",
    "for name in dataset_names:\n",
    "    file_path = os.path.join(load_dir, f\"{name}.pkl\")\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        loaded_data[name] = pickle.load(f)\n",
    "    print(f\" Wczytano: {file_path}\")\n",
    "\n",
    "X_img_train = loaded_data[\"X_img_train\"]\n",
    "X_img_test = loaded_data[\"X_img_test\"]\n",
    "X_meta_train = loaded_data[\"X_meta_train\"]\n",
    "X_meta_test = loaded_data[\"X_meta_test\"]\n",
    "y_train_enc = loaded_data[\"y_train_enc\"]\n",
    "y_test_enc = loaded_data[\"y_test_enc\"]\n",
    "le = loaded_data[\"label_encoder\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hzOfF84wk4wC",
   "metadata": {
    "executionInfo": {
     "elapsed": 4959,
     "status": "ok",
     "timestamp": 1749315517357,
     "user": {
      "displayName": "Aleksandra Hendrysiak",
      "userId": "02783590481816071264"
     },
     "user_tz": -120
    },
    "id": "hzOfF84wk4wC"
   },
   "outputs": [],
   "source": [
    "col_means = np.nanmean(X_meta_test, axis=0)\n",
    "inds = np.where(np.isnan(X_meta_test))\n",
    "X_meta_test[inds] = np.take(col_means, inds[1])\n",
    "\n",
    "col_means = np.nanmean(X_meta_train, axis=0)\n",
    "inds = np.where(np.isnan(X_meta_train))\n",
    "X_meta_train[inds] = np.take(col_means, inds[1])\n",
    "\n",
    "X_img_train_flat = X_img_train.reshape(X_img_train.shape[0], -1)\n",
    "X_img_test_flat = X_img_test.reshape(X_img_test.shape[0], -1)\n",
    "X_train_combined = np.concatenate([X_img_train_flat, X_meta_train], axis=1)\n",
    "X_test_combined = np.concatenate([X_img_test_flat, X_meta_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1vZ7VBgU-v-",
   "metadata": {
    "executionInfo": {
     "elapsed": 5529,
     "status": "ok",
     "timestamp": 1749315588018,
     "user": {
      "displayName": "Aleksandra Hendrysiak",
      "userId": "02783590481816071264"
     },
     "user_tz": -120
    },
    "id": "f1vZ7VBgU-v-"
   },
   "outputs": [],
   "source": [
    "X_train_new, X_val, y_train_new, y_val = train_test_split(\n",
    "    X_train_combined, y_train_enc, test_size=0.1, random_state=42, stratify=y_train_enc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "_6toJ1EoVZ8i",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1749315601060,
     "user": {
      "displayName": "Aleksandra Hendrysiak",
      "userId": "02783590481816071264"
     },
     "user_tz": -120
    },
    "id": "_6toJ1EoVZ8i",
    "outputId": "8b60eb66-070f-4f66-af72-6d4a57df9047"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(672, 150533)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OqE9V8WsilLj",
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1749286800204,
     "user": {
      "displayName": "Aleksandra Hendrysiak",
      "userId": "02783590481816071264"
     },
     "user_tz": -120
    },
    "id": "OqE9V8WsilLj"
   },
   "outputs": [],
   "source": [
    "model_classes = [\n",
    "    ('KNN_D', KNeighborsClassifier()),\n",
    "    ('DecisionTree_D', DecisionTreeClassifier()),\n",
    "    ('RandomForest_D', RandomForestClassifier()),\n",
    "    ('LogisticRegression_D', LogisticRegression())\n",
    "]\n",
    "\n",
    "param_grid = {\n",
    "    'KNN_D': [{'n_neighbors': k} for k in [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]],\n",
    "    'DecisionTree_D': [{'max_depth': d} for d in [5, 10, 15, 20, 25, 30, None]],\n",
    "    'RandomForest_D': [{'n_estimators': n, 'max_depth': d, 'max_features': 'sqrt'} for n in [50, 100, 1000] for d in [10, 20]],\n",
    "}\n",
    "\n",
    "def classical_sim(X_train, X_test, y_train, y_test, param=120):\n",
    "    results = []\n",
    "\n",
    "    for name, model in model_classes:\n",
    "        print(f\"\\n{name} - training...\")\n",
    "\n",
    "        for param_set in param_grid.get(name, []):\n",
    "            print(f\"Testing with parameters: {param_set}\")\n",
    "\n",
    "            start_time = time.time()\n",
    "\n",
    "            model.set_params(**param_set)\n",
    "\n",
    "            print(f\"\\n{name} - training...\")\n",
    "\n",
    "            model.fit(X_train_combined, y_train_enc)\n",
    "            end_time = time.time()\n",
    "            training_time = end_time - start_time\n",
    "\n",
    "            preds = model.predict(X_test_combined)\n",
    "            acc_preview = accuracy_score(y_test_enc, preds)\n",
    "\n",
    "            y_prob = model.predict(X_test_combined)\n",
    "            y_pred = np.argmax(y_prob, axis=1)\n",
    "            #y_pred = y_prob\n",
    "            y_true = np.argmax(y_test_enc, axis=1)\n",
    "\n",
    "            accuracy = accuracy_score(y_true, y_pred)\n",
    "            report = classification_report(y_true, y_pred)\n",
    "\n",
    "            with open(f\"/content/drive/MyDrive/Master - A/3_fig/{param}_{name}_results.txt\", \"w\") as f:\n",
    "                f.write(f\"Model: {name}\\n\")\n",
    "                f.write(f\"Training time: {training_time:.2f} sec\\n\")\n",
    "                f.write(f\"Accuracy: {accuracy:.4f}\\n\\n\")\n",
    "                f.write(\"Classification Report:\\n\")\n",
    "                f.write(report)\n",
    "\n",
    "            conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "            plt.title(\"Confusion Matrix\")\n",
    "            plt.xlabel(\"Predicted\")\n",
    "            plt.ylabel(\"Actual\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"/content/drive/MyDrive/Master - A/3_fig/{param}_{name}_matrix.png\")\n",
    "            plt.close()\n",
    "\n",
    "            fpr, tpr, _ = roc_curve(y_true, y_prob[:, 1]) if y_prob.shape[1] == 2 else (None, None, None)\n",
    "            if fpr is not None:\n",
    "                roc_auc = auc(fpr, tpr)\n",
    "                plt.figure(figsize=(8, 6))\n",
    "                plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})', lw=2)\n",
    "                plt.plot([0, 1], [0, 1], 'k--')\n",
    "                plt.xlabel('False Positive Rate')\n",
    "                plt.ylabel('True Positive Rate')\n",
    "                plt.legend()\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f\"/content/drive/MyDrive/Master - A/3_fig/{param}_{name}_roc_curve.png\")\n",
    "                plt.close()\n",
    "\n",
    "            results.append((name, accuracy))\n",
    "\n",
    "            del preds\n",
    "            gc.collect()\n",
    "\n",
    "        with open(f\"/content/drive/MyDrive/Master - A/3_fig/{param}_final_results.csv\", mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Model\", \"Accuracy\"])\n",
    "            for name, acc in results:\n",
    "                writer.writerow([name, f\"{acc:.4f}\"])\n",
    "\n",
    "        print(\"\\nFinal Results:\")\n",
    "        for name, acc in results:\n",
    "            print(f\"{name}: {acc:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "SwRa0-_gjUnA",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1749285689119,
     "user": {
      "displayName": "Aleksandra Hendrysiak",
      "userId": "02783590481816071264"
     },
     "user_tz": -120
    },
    "id": "SwRa0-_gjUnA"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Sga0MtYfivy7",
   "metadata": {
    "id": "Sga0MtYfivy7"
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1BaiZLqRiujM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11129141,
     "status": "ok",
     "timestamp": 1749302157960,
     "user": {
      "displayName": "Aleksandra Hendrysiak",
      "userId": "02783590481816071264"
     },
     "user_tz": -120
    },
    "id": "1BaiZLqRiujM",
    "outputId": "27854fe4-744d-4655-c4db-461fbc3ede4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KNN_D - training...\n",
      "Testing with parameters: {'n_neighbors': 10}\n",
      "\n",
      "KNN_D - training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with parameters: {'n_neighbors': 11}\n",
      "\n",
      "KNN_D - training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with parameters: {'n_neighbors': 12}\n",
      "\n",
      "KNN_D - training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with parameters: {'n_neighbors': 13}\n",
      "\n",
      "KNN_D - training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with parameters: {'n_neighbors': 14}\n",
      "\n",
      "KNN_D - training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with parameters: {'n_neighbors': 15}\n",
      "\n",
      "KNN_D - training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with parameters: {'n_neighbors': 16}\n",
      "\n",
      "KNN_D - training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with parameters: {'n_neighbors': 17}\n",
      "\n",
      "KNN_D - training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with parameters: {'n_neighbors': 18}\n",
      "\n",
      "KNN_D - training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with parameters: {'n_neighbors': 19}\n",
      "\n",
      "KNN_D - training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with parameters: {'n_neighbors': 20}\n",
      "\n",
      "KNN_D - training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with parameters: {'n_neighbors': 21}\n",
      "\n",
      "KNN_D - training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with parameters: {'n_neighbors': 22}\n",
      "\n",
      "KNN_D - training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with parameters: {'n_neighbors': 23}\n",
      "\n",
      "KNN_D - training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with parameters: {'n_neighbors': 24}\n",
      "\n",
      "KNN_D - training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with parameters: {'n_neighbors': 25}\n",
      "\n",
      "KNN_D - training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Results:\n",
      "KNN_D: 0.1536\n",
      "KNN_D: 0.1643\n",
      "KNN_D: 0.1458\n",
      "KNN_D: 0.1595\n",
      "KNN_D: 0.1446\n",
      "KNN_D: 0.1554\n",
      "KNN_D: 0.1452\n",
      "KNN_D: 0.1530\n",
      "KNN_D: 0.1440\n",
      "KNN_D: 0.1512\n",
      "KNN_D: 0.1423\n",
      "KNN_D: 0.1476\n",
      "KNN_D: 0.1399\n",
      "KNN_D: 0.1435\n",
      "KNN_D: 0.1375\n",
      "KNN_D: 0.1435\n",
      "\n",
      "DecisionTree_D - training...\n",
      "Testing with parameters: {'max_depth': 5}\n",
      "\n",
      "DecisionTree_D - training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with parameters: {'max_depth': 10}\n",
      "\n",
      "DecisionTree_D - training...\n",
      "Testing with parameters: {'max_depth': 15}\n",
      "\n",
      "DecisionTree_D - training...\n",
      "Testing with parameters: {'max_depth': 20}\n",
      "\n",
      "DecisionTree_D - training...\n",
      "Testing with parameters: {'max_depth': 25}\n",
      "\n",
      "DecisionTree_D - training...\n",
      "Testing with parameters: {'max_depth': 30}\n",
      "\n",
      "DecisionTree_D - training...\n",
      "Testing with parameters: {'max_depth': None}\n",
      "\n",
      "DecisionTree_D - training...\n",
      "\n",
      "Final Results:\n",
      "KNN_D: 0.1536\n",
      "KNN_D: 0.1643\n",
      "KNN_D: 0.1458\n",
      "KNN_D: 0.1595\n",
      "KNN_D: 0.1446\n",
      "KNN_D: 0.1554\n",
      "KNN_D: 0.1452\n",
      "KNN_D: 0.1530\n",
      "KNN_D: 0.1440\n",
      "KNN_D: 0.1512\n",
      "KNN_D: 0.1423\n",
      "KNN_D: 0.1476\n",
      "KNN_D: 0.1399\n",
      "KNN_D: 0.1435\n",
      "KNN_D: 0.1375\n",
      "KNN_D: 0.1435\n",
      "DecisionTree_D: 0.2833\n",
      "DecisionTree_D: 0.2946\n",
      "DecisionTree_D: 0.3042\n",
      "DecisionTree_D: 0.3327\n",
      "DecisionTree_D: 0.3196\n",
      "DecisionTree_D: 0.3452\n",
      "DecisionTree_D: 0.3274\n",
      "\n",
      "RandomForest_D - training...\n",
      "Testing with parameters: {'n_estimators': 50, 'max_depth': 10, 'max_features': 'sqrt'}\n",
      "\n",
      "RandomForest_D - training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with parameters: {'n_estimators': 50, 'max_depth': 20, 'max_features': 'sqrt'}\n",
      "\n",
      "RandomForest_D - training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with parameters: {'n_estimators': 100, 'max_depth': 10, 'max_features': 'sqrt'}\n",
      "\n",
      "RandomForest_D - training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with parameters: {'n_estimators': 100, 'max_depth': 20, 'max_features': 'sqrt'}\n",
      "\n",
      "RandomForest_D - training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with parameters: {'n_estimators': 1000, 'max_depth': 10, 'max_features': 'sqrt'}\n",
      "\n",
      "RandomForest_D - training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with parameters: {'n_estimators': 1000, 'max_depth': 20, 'max_features': 'sqrt'}\n",
      "\n",
      "RandomForest_D - training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Results:\n",
      "KNN_D: 0.1536\n",
      "KNN_D: 0.1643\n",
      "KNN_D: 0.1458\n",
      "KNN_D: 0.1595\n",
      "KNN_D: 0.1446\n",
      "KNN_D: 0.1554\n",
      "KNN_D: 0.1452\n",
      "KNN_D: 0.1530\n",
      "KNN_D: 0.1440\n",
      "KNN_D: 0.1512\n",
      "KNN_D: 0.1423\n",
      "KNN_D: 0.1476\n",
      "KNN_D: 0.1399\n",
      "KNN_D: 0.1435\n",
      "KNN_D: 0.1375\n",
      "KNN_D: 0.1435\n",
      "DecisionTree_D: 0.2833\n",
      "DecisionTree_D: 0.2946\n",
      "DecisionTree_D: 0.3042\n",
      "DecisionTree_D: 0.3327\n",
      "DecisionTree_D: 0.3196\n",
      "DecisionTree_D: 0.3452\n",
      "DecisionTree_D: 0.3274\n",
      "RandomForest_D: 0.1262\n",
      "RandomForest_D: 0.1381\n",
      "RandomForest_D: 0.1286\n",
      "RandomForest_D: 0.1339\n",
      "RandomForest_D: 0.1256\n",
      "RandomForest_D: 0.1327\n",
      "\n",
      "LogisticRegression_D - training...\n",
      "\n",
      "Final Results:\n",
      "KNN_D: 0.1536\n",
      "KNN_D: 0.1643\n",
      "KNN_D: 0.1458\n",
      "KNN_D: 0.1595\n",
      "KNN_D: 0.1446\n",
      "KNN_D: 0.1554\n",
      "KNN_D: 0.1452\n",
      "KNN_D: 0.1530\n",
      "KNN_D: 0.1440\n",
      "KNN_D: 0.1512\n",
      "KNN_D: 0.1423\n",
      "KNN_D: 0.1476\n",
      "KNN_D: 0.1399\n",
      "KNN_D: 0.1435\n",
      "KNN_D: 0.1375\n",
      "KNN_D: 0.1435\n",
      "DecisionTree_D: 0.2833\n",
      "DecisionTree_D: 0.2946\n",
      "DecisionTree_D: 0.3042\n",
      "DecisionTree_D: 0.3327\n",
      "DecisionTree_D: 0.3196\n",
      "DecisionTree_D: 0.3452\n",
      "DecisionTree_D: 0.3274\n",
      "RandomForest_D: 0.1262\n",
      "RandomForest_D: 0.1381\n",
      "RandomForest_D: 0.1286\n",
      "RandomForest_D: 0.1339\n",
      "RandomForest_D: 0.1256\n",
      "RandomForest_D: 0.1327\n"
     ]
    }
   ],
   "source": [
    "classical_sim(X_train_combined, X_test_combined, y_train_enc, y_test_enc, param = \"june\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sUL-OcgaS6mn",
   "metadata": {
    "id": "sUL-OcgaS6mn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ve4KVMKEPqw8",
   "metadata": {
    "id": "Ve4KVMKEPqw8"
   },
   "outputs": [],
   "source": [
    "classical_sim(X_train_combined, X_test_combined, y_train_enc, y_test_enc, param = \"june2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tbRk0pRJPyJN",
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1749314194996,
     "user": {
      "displayName": "Aleksandra Hendrysiak",
      "userId": "02783590481816071264"
     },
     "user_tz": -120
    },
    "id": "tbRk0pRJPyJN"
   },
   "outputs": [],
   "source": [
    "model_classes = [\n",
    "    ('KNN_D', KNeighborsClassifier()),\n",
    "    #('DecisionTree_D', DecisionTreeClassifier()),\n",
    "    #('RandomForest_D', RandomForestClassifier()),\n",
    "    #('LogisticRegression_D', LogisticRegression())\n",
    "]\n",
    "\n",
    "param_grid = {\n",
    "    'KNN_D': [{'n_neighbors': k} for k in [3, 4, 5, 6,7, 8,9, 10]],\n",
    "    #'DecisionTree_D': [{'max_depth': d} for d in [5, 10, 15, 20, 25, 30, None]],\n",
    "    #'RandomForest_D': [{'n_estimators': n, 'max_depth': d, 'max_features': 'sqrt'} for n in [50, 100, 1000] for d in [10, 20]],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NmDiE8AZS_og",
   "metadata": {
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1749316948259,
     "user": {
      "displayName": "Aleksandra Hendrysiak",
      "userId": "02783590481816071264"
     },
     "user_tz": -120
    },
    "id": "NmDiE8AZS_og"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import gc\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, classification_report,\n",
    "    confusion_matrix, roc_curve, auc\n",
    ")\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def classical_sim_grid(X_val, y_val, X_train, X_test, y_train, y_test, param=\"grid\"):\n",
    "    results = []\n",
    "\n",
    "    model_classes = {\n",
    "        'KNN_D': (KNeighborsClassifier(), {\n",
    "            'n_neighbors': list(range(3, 26))\n",
    "        }),\n",
    "        'DecisionTree_D': (DecisionTreeClassifier(), {\n",
    "            'max_depth': [5, 10, 15, 20, 25, 30, None]\n",
    "        }),\n",
    "        'RandomForest_D': (RandomForestClassifier(), {\n",
    "            'n_estimators': [50, 100, 1000],\n",
    "            'max_depth': [10, 20],\n",
    "            'max_features': ['sqrt']\n",
    "        }),\n",
    "        'LogisticRegression_D': (LogisticRegression(max_iter=1000), {})  # domyślnie, brak gridu\n",
    "    }\n",
    "\n",
    "    for name, (model, param_grid) in model_classes.items():\n",
    "        print(f\"\\n{name} - Grid Search...\")\n",
    "\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=model,\n",
    "            param_grid=param_grid,\n",
    "            scoring='accuracy',\n",
    "            cv=3,\n",
    "            n_jobs=-1,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        start_time = time.time()\n",
    "        grid_search.fit(X_val, y_val)\n",
    "        training_time = time.time() - start_time\n",
    "\n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_params = grid_search.best_params_\n",
    "        print(f\"Best params: {best_params}\")\n",
    "\n",
    "        start_time = time.time()\n",
    "        model.set_params(**best_params)\n",
    "        model.fit(X_train, y_train)\n",
    "        end_time = time.time()\n",
    "        training_time = end_time - start_time\n",
    "\n",
    "        preds = model.predict(X_test_combined)\n",
    "        acc_preview = accuracy_score(y_test_enc, preds)\n",
    "\n",
    "        y_prob = model.predict(X_test_combined)\n",
    "        #y_pred = np.argmax(y_prob, axis=1)\n",
    "        y_pred = y_prob\n",
    "        y_true = y_test_enc\n",
    "        #y_true = np.argmax(y_test_enc, axis=1)\n",
    "\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        report = classification_report(y_true, y_pred)\n",
    "\n",
    "        filename_prefix = f\"/content/drive/MyDrive/Master - A/2_fig/{param}_{name}\"\n",
    "        with open(f\"{filename_prefix}_results.txt\", \"w\") as f:\n",
    "            f.write(f\"Model: {name}\\n\")\n",
    "            f.write(f\"Best Parameters: {best_params}\\n\")\n",
    "            f.write(f\"Training time: {training_time:.2f} sec\\n\")\n",
    "            f.write(f\"Accuracy: {accuracy:.4f}\\n\\n\")\n",
    "            f.write(\"Classification Report:\\n\")\n",
    "            f.write(report)\n",
    "\n",
    "        conf_matrix = confusion_matrix(y_test, preds)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "        plt.title(f\"{name} - Confusion Matrix\")\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{filename_prefix}_matrix.png\")\n",
    "        plt.close()\n",
    "\n",
    "        try:\n",
    "            if len(np.unique(y_test)) == 2:\n",
    "                y_score = best_model.predict_proba(X_test)[:, 1]\n",
    "                fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "                roc_auc = auc(fpr, tpr)\n",
    "\n",
    "                plt.figure(figsize=(8, 6))\n",
    "                plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC (AUC = {roc_auc:.2f})')\n",
    "                plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "                plt.xlabel('False Positive Rate')\n",
    "                plt.ylabel('True Positive Rate')\n",
    "                plt.title('ROC Curve')\n",
    "                plt.legend(loc=\"lower right\")\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f\"{filename_prefix}_roc_curve.png\")\n",
    "                plt.close()\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ ROC failed: {e}\")\n",
    "\n",
    "        results.append((name, best_params, accuracy))\n",
    "\n",
    "        del grid_search, best_model, preds, conf_matrix\n",
    "        gc.collect()\n",
    "\n",
    "    with open(f\"/content/drive/MyDrive/Master - A/2_fig/{param}_final_results.csv\", mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Model\", \"Best Parameters\", \"Accuracy\"])\n",
    "        for name, best_params, acc in results:\n",
    "            writer.writerow([name, str(best_params), f\"{acc:.4f}\"])\n",
    "\n",
    "    print(\"\\nFinal Results:\")\n",
    "    for name, best_params, acc in results:\n",
    "        print(f\"{name} with best parameters {best_params}: {acc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "YVkxNf7WQHqa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 392698,
     "status": "ok",
     "timestamp": 1749314628728,
     "user": {
      "displayName": "Aleksandra Hendrysiak",
      "userId": "02783590481816071264"
     },
     "user_tz": -120
    },
    "id": "YVkxNf7WQHqa",
    "outputId": "5a2f9c27-1b65-46f8-a753-f4baa9202fad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KNN_D - training...\n",
      "Testing with parameters: {'n_neighbors': 3}\n",
      "\n",
      "KNN_D - training...\n",
      "Testing with parameters: {'n_neighbors': 4}\n",
      "\n",
      "KNN_D - training...\n",
      "Testing with parameters: {'n_neighbors': 5}\n",
      "\n",
      "KNN_D - training...\n",
      "Testing with parameters: {'n_neighbors': 6}\n",
      "\n",
      "KNN_D - training...\n",
      "Testing with parameters: {'n_neighbors': 7}\n",
      "\n",
      "KNN_D - training...\n",
      "Testing with parameters: {'n_neighbors': 8}\n",
      "\n",
      "KNN_D - training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with parameters: {'n_neighbors': 9}\n",
      "\n",
      "KNN_D - training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with parameters: {'n_neighbors': 10}\n",
      "\n",
      "KNN_D - training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Results:\n",
      "KNN_D: 0.2018\n",
      "KNN_D: 0.1643\n",
      "KNN_D: 0.1869\n",
      "KNN_D: 0.1613\n",
      "KNN_D: 0.1810\n",
      "KNN_D: 0.1554\n",
      "KNN_D: 0.1708\n",
      "KNN_D: 0.1536\n"
     ]
    }
   ],
   "source": [
    "classical_sim(X_train_combined, X_test_combined, y_train_enc, y_test_enc, param = \"june2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FEgeCafXS9tm",
   "metadata": {
    "id": "FEgeCafXS9tm"
   },
   "source": [
    "#GRID SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7oRIpWCXTDBy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5986134,
     "status": "ok",
     "timestamp": 1749322939468,
     "user": {
      "displayName": "Aleksandra Hendrysiak",
      "userId": "02783590481816071264"
     },
     "user_tz": -120
    },
    "id": "7oRIpWCXTDBy",
    "outputId": "a2127a2c-e6fc-43ea-8f4f-350761a2713e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KNN_D - Grid Search...\n",
      "Fitting 3 folds for each of 23 candidates, totalling 69 fits\n",
      "Best params: {'n_neighbors': 20}\n",
      "\n",
      "DecisionTree_D - Grid Search...\n",
      "Fitting 3 folds for each of 7 candidates, totalling 21 fits\n",
      "Best params: {'max_depth': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomForest_D - Grid Search...\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "Best params: {'max_depth': 20, 'max_features': 'sqrt', 'n_estimators': 1000}\n",
      "\n",
      "LogisticRegression_D - Grid Search...\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Results:\n",
      "KNN_D with best parameters {'n_neighbors': 20}: 0.2554\n",
      "DecisionTree_D with best parameters {'max_depth': 5}: 0.3375\n",
      "RandomForest_D with best parameters {'max_depth': 20, 'max_features': 'sqrt', 'n_estimators': 1000}: 0.4137\n",
      "LogisticRegression_D with best parameters {}: 0.4071\n"
     ]
    }
   ],
   "source": [
    "y_train_enc = np.argmax(y_train_enc, axis=1) if len(y_train_enc.shape) > 1 else y_train_enc\n",
    "y_test_enc = np.argmax(y_test_enc, axis=1) if len(y_test_enc.shape) > 1 else y_test_enc\n",
    "y_val = np.argmax(y_val, axis=1) if len(y_val.shape) > 1 else y_val\n",
    "classical_sim_grid(X_val, y_val, X_train_combined, X_test_combined, y_train_enc, y_test_enc, param = \"grid_juneeee\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "G94hq9A_XB8x",
   "metadata": {
    "id": "G94hq9A_XB8x"
   },
   "source": [
    "## CNNN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ee776d",
   "metadata": {
    "id": "f3ee776d"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "random.seed(42)\n",
    "from sklearn.metrics import classification_report, accuracy_score,confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import (\n",
    "    VGG16, VGG19, ResNet50, InceptionV3, Xception,\n",
    "    MobileNet, MobileNetV2, MobileNetV3Large, DenseNet121, DenseNet169, NASNetMobile,\n",
    "    EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB7\n",
    ")\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616f560b",
   "metadata": {
    "id": "616f560b"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath='best_cnn_model.keras', \n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48503a0",
   "metadata": {
    "id": "f48503a0"
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=6,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 70\n",
    "\n",
    "\n",
    "model_classes = [\n",
    "    InceptionV3, Xception, MobileNet,MobileNetV2,\n",
    "    DenseNet121, VGG16\n",
    "]\n",
    "\n",
    "model_names = [\n",
    "    \"InceptionV3\", \"Xception\", \"MobileNet\", \"MobileNetV2\",\n",
    "    \"DenseNet121\", \"VGG16\"\n",
    "]\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc4c3b9",
   "metadata": {
    "id": "5fc4c3b9"
   },
   "outputs": [],
   "source": [
    "def my_cnn(input_shape=(224, 224, 3), num_classes=10):\n",
    "    model = models.Sequential()\n",
    "\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-1J8A8vtpRox",
   "metadata": {
    "id": "-1J8A8vtpRox"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfbd9c6",
   "metadata": {
    "id": "ecfbd9c6"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc\n",
    "from tensorflow.keras import models, layers\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "def cnn_sim(x_train, x_test, y_train, y_test, param):\n",
    "    results = []\n",
    "\n",
    "    for model_class, name in zip(model_classes, model_names):\n",
    "        print(f\"\\n{name}\")\n",
    "\n",
    "        base_model = model_class(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "        base_model.trainable = False  \n",
    "\n",
    "        model = models.Sequential([\n",
    "            base_model,\n",
    "            layers.GlobalAveragePooling2D(),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dropout(0.5),\n",
    "            layers.Dense(len(le.classes_), activation='softmax')  \n",
    "        ])\n",
    "\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        start_time = time.time()\n",
    "        history = model.fit(\n",
    "            x_train, y_train,\n",
    "            epochs=70,\n",
    "            batch_size=64,\n",
    "            validation_split=0.2,\n",
    "            verbose=2,\n",
    "            callbacks=[early_stopping]\n",
    "        )\n",
    "        end_time = time.time()\n",
    "        training_time = end_time - start_time\n",
    "        print(f\"Training time: {training_time:.2f} seconds\")\n",
    "\n",
    "        loss, acc = model.evaluate(x_test, y_test)\n",
    "        print(f\"{name} - Test accuracy: {acc:.4f}\")\n",
    "\n",
    "        y_prob = model.predict(x_test)\n",
    "        y_pred = np.argmax(y_prob, axis=1)\n",
    "        y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "        with open(f\"/content/drive/MyDrive/Master - A/3_fig/{param}_{name}_results.txt\", \"w\") as f:\n",
    "            f.write(f\"Model: {name}\\n\")\n",
    "            f.write(f\"Training time: {training_time:.2f} sec\\n\")\n",
    "            f.write(f\"Accuracy: {acc:.4f}\\n\\n\")\n",
    "            f.write(\"Classification Report:\\n\")\n",
    "\n",
    "        conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"/content/drive/MyDrive/Master - A/3_fig/{param}_{name}_matrix.png\")\n",
    "        plt.close()\n",
    "\n",
    "        model.save(f'/content/drive/MyDrive/Master - A/3_fig/{param}_{name}_model.h5')\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(history.history['loss'], label='Train Loss')\n",
    "        plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "        plt.xlabel('Epochs', fontsize=18)\n",
    "        plt.ylabel('Loss', fontsize=18)\n",
    "        plt.xticks(fontsize=18)\n",
    "        plt.yticks(fontsize=18)\n",
    "        plt.tight_layout()\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"/content/drive/MyDrive/Master - A/3_fig/{param}_{name}_train_val_loss.png\")\n",
    "        plt.close()\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "        plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "        plt.xlabel('Epochs', fontsize=18)\n",
    "        plt.ylabel('Accuracy', fontsize=18)\n",
    "        plt.xticks(fontsize=18)\n",
    "        plt.yticks(fontsize=18)\n",
    "        plt.tight_layout()\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"/content/drive/MyDrive/Master - A/3_fig/{param}_{name}_train_val_accuracy.png\")\n",
    "        plt.close()\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_prob[:, 1])  \n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        plt.xlabel('False Positive Rate', fontsize=18)\n",
    "        plt.ylabel('True Positive Rate', fontsize=18)\n",
    "        plt.xticks(fontsize=18)\n",
    "        plt.yticks(fontsize=18)\n",
    "        plt.tight_layout()\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.savefig(f\"/content/drive/MyDrive/Master - A/3_fig/{param}_{name}_roc_curve.png\")\n",
    "        plt.close()\n",
    "\n",
    "        results.append({\n",
    "            'Model': name,\n",
    "            'Test Accuracy': acc,\n",
    "            'Training Time (s)': training_time\n",
    "        })\n",
    "\n",
    "    model = my_cnn(num_classes=len(le.classes_))\n",
    "    name = \"my\"\n",
    "\n",
    "    start_time = time.time()\n",
    "    history = model.fit(x_train, y_train, epochs=70, batch_size=32,\n",
    "                        validation_split=0.2, verbose=1, callbacks=[early_stopping])\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    print(f\"Training time: {training_time:.2f} seconds\")\n",
    "\n",
    "    test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "    print(f\"Test accuracy: {test_acc:.4f}\")\n",
    "\n",
    "    y_prob = model.predict(x_test)\n",
    "    y_pred = np.argmax(y_prob, axis=1)\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"/content/drive/MyDrive/Master - A/3_fig/{param}_{name}_matrix.png\")\n",
    "    plt.close()\n",
    "\n",
    "    model.save(f'/content/drive/MyDrive/Master - A/3_fig/{param}_{name}_model.h5')\n",
    "\n",
    "    file_path = f\"/content/drive/MyDrive/Master - A/3_fig/{param}_{name}_history.pkl\"\n",
    "    with open(file_path, 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epochs', fontsize=18)\n",
    "    plt.ylabel('Loss', fontsize=18)\n",
    "    plt.xticks(fontsize=18)\n",
    "    plt.yticks(fontsize=18)\n",
    "    plt.tight_layout()\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"/content/drive/MyDrive/Master - A/3_fig/{param}_{name}_train_val_loss.png\")\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.xlabel('Epochs', fontsize=18)\n",
    "    plt.ylabel('Accuracy', fontsize=18)\n",
    "    plt.xticks(fontsize=18)\n",
    "    plt.yticks(fontsize=18)\n",
    "    plt.tight_layout()\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"/content/drive/MyDrive/Master - A/3_fig/{param}_{name}_train_val_accuracy.png\")\n",
    "    plt.close()\n",
    "\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Test Accuracy': test_acc,\n",
    "        'Training Time (s)': training_time\n",
    "    })\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(f'/content/drive/MyDrive/Master - A/3_fig/{param}_model_training_results.csv', index=False)\n",
    "    print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82d36e0",
   "metadata": {
    "id": "a82d36e0"
   },
   "source": [
    "### Bez meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "O7iaeNpXrfV_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1937038,
     "status": "ok",
     "timestamp": 1749156086609,
     "user": {
      "displayName": "Aleksandra Hendrysiak",
      "userId": "02783590481816071264"
     },
     "user_tz": -120
    },
    "id": "O7iaeNpXrfV_",
    "outputId": "a27ece8b-f6e7-416f-b74f-58f7e0983637"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "InceptionV3\n",
      "Epoch 1/70\n",
      "84/84 - 30s - 351ms/step - accuracy: 0.4018 - loss: 1.6580 - val_accuracy: 0.6064 - val_loss: 1.1429\n",
      "Epoch 2/70\n",
      "84/84 - 5s - 59ms/step - accuracy: 0.5522 - loss: 1.1888 - val_accuracy: 0.6384 - val_loss: 0.9978\n",
      "Epoch 3/70\n",
      "84/84 - 5s - 59ms/step - accuracy: 0.6066 - loss: 1.0241 - val_accuracy: 0.6823 - val_loss: 0.8744\n",
      "Epoch 4/70\n",
      "84/84 - 5s - 59ms/step - accuracy: 0.6289 - loss: 0.9429 - val_accuracy: 0.6935 - val_loss: 0.8291\n",
      "Epoch 5/70\n",
      "84/84 - 5s - 59ms/step - accuracy: 0.6771 - loss: 0.8661 - val_accuracy: 0.6815 - val_loss: 0.8214\n",
      "Epoch 6/70\n",
      "84/84 - 5s - 59ms/step - accuracy: 0.6752 - loss: 0.8416 - val_accuracy: 0.7217 - val_loss: 0.7637\n",
      "Epoch 7/70\n",
      "84/84 - 5s - 57ms/step - accuracy: 0.7067 - loss: 0.7590 - val_accuracy: 0.7039 - val_loss: 0.7817\n",
      "Epoch 8/70\n",
      "84/84 - 5s - 57ms/step - accuracy: 0.7182 - loss: 0.7403 - val_accuracy: 0.7158 - val_loss: 0.7703\n",
      "Epoch 9/70\n",
      "84/84 - 5s - 60ms/step - accuracy: 0.7268 - loss: 0.7180 - val_accuracy: 0.7068 - val_loss: 0.7504\n",
      "Epoch 10/70\n",
      "84/84 - 5s - 60ms/step - accuracy: 0.7376 - loss: 0.6972 - val_accuracy: 0.7240 - val_loss: 0.7423\n",
      "Epoch 11/70\n",
      "84/84 - 5s - 59ms/step - accuracy: 0.7344 - loss: 0.6763 - val_accuracy: 0.7269 - val_loss: 0.7379\n",
      "Epoch 12/70\n",
      "84/84 - 5s - 60ms/step - accuracy: 0.7512 - loss: 0.6405 - val_accuracy: 0.7292 - val_loss: 0.7340\n",
      "Epoch 13/70\n",
      "84/84 - 5s - 58ms/step - accuracy: 0.7610 - loss: 0.6246 - val_accuracy: 0.7247 - val_loss: 0.7444\n",
      "Epoch 14/70\n",
      "84/84 - 5s - 60ms/step - accuracy: 0.7653 - loss: 0.6092 - val_accuracy: 0.7381 - val_loss: 0.7339\n",
      "Epoch 15/70\n",
      "84/84 - 5s - 58ms/step - accuracy: 0.7735 - loss: 0.5813 - val_accuracy: 0.7247 - val_loss: 0.7556\n",
      "Epoch 16/70\n",
      "84/84 - 5s - 57ms/step - accuracy: 0.7856 - loss: 0.5491 - val_accuracy: 0.7188 - val_loss: 0.7678\n",
      "Epoch 17/70\n",
      "84/84 - 5s - 58ms/step - accuracy: 0.7865 - loss: 0.5427 - val_accuracy: 0.7202 - val_loss: 0.7641\n",
      "Epoch 18/70\n",
      "84/84 - 5s - 58ms/step - accuracy: 0.7966 - loss: 0.5262 - val_accuracy: 0.7262 - val_loss: 0.7448\n",
      "Epoch 19/70\n",
      "84/84 - 5s - 58ms/step - accuracy: 0.8050 - loss: 0.4967 - val_accuracy: 0.7254 - val_loss: 0.7407\n",
      "Epoch 20/70\n",
      "84/84 - 5s - 58ms/step - accuracy: 0.8100 - loss: 0.4861 - val_accuracy: 0.7195 - val_loss: 0.7952\n",
      "Training time: 127.87 seconds\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 84ms/step - accuracy: 0.7377 - loss: 0.6719\n",
      "InceptionV3 - Test accuracy: 0.7387\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 132ms/step\n",
      "[4 4 1 ... 0 3 6]\n",
      "[4 4 1 ... 0 3 6]\n",
      "Accuracy: 0.7387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Xception\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m83683744/83683744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n",
      "Epoch 1/70\n",
      "84/84 - 44s - 526ms/step - accuracy: 0.5038 - loss: 1.3252 - val_accuracy: 0.6503 - val_loss: 0.9351\n",
      "Epoch 2/70\n",
      "84/84 - 10s - 119ms/step - accuracy: 0.6438 - loss: 0.9176 - val_accuracy: 0.6920 - val_loss: 0.8059\n",
      "Epoch 3/70\n",
      "84/84 - 10s - 119ms/step - accuracy: 0.6948 - loss: 0.7948 - val_accuracy: 0.7202 - val_loss: 0.7403\n",
      "Epoch 4/70\n",
      "84/84 - 10s - 119ms/step - accuracy: 0.7294 - loss: 0.7135 - val_accuracy: 0.7307 - val_loss: 0.7053\n",
      "Epoch 5/70\n",
      "84/84 - 10s - 120ms/step - accuracy: 0.7523 - loss: 0.6484 - val_accuracy: 0.7277 - val_loss: 0.7039\n",
      "Epoch 6/70\n",
      "84/84 - 10s - 119ms/step - accuracy: 0.7675 - loss: 0.6084 - val_accuracy: 0.7299 - val_loss: 0.6822\n",
      "Epoch 7/70\n",
      "84/84 - 10s - 120ms/step - accuracy: 0.7765 - loss: 0.5654 - val_accuracy: 0.7426 - val_loss: 0.6771\n",
      "Epoch 8/70\n",
      "84/84 - 10s - 119ms/step - accuracy: 0.8042 - loss: 0.5227 - val_accuracy: 0.7321 - val_loss: 0.6831\n",
      "Epoch 9/70\n",
      "84/84 - 10s - 120ms/step - accuracy: 0.8068 - loss: 0.5025 - val_accuracy: 0.7433 - val_loss: 0.6662\n",
      "Epoch 10/70\n",
      "84/84 - 10s - 118ms/step - accuracy: 0.8187 - loss: 0.4691 - val_accuracy: 0.7470 - val_loss: 0.6697\n",
      "Epoch 11/70\n",
      "84/84 - 10s - 119ms/step - accuracy: 0.8375 - loss: 0.4347 - val_accuracy: 0.7515 - val_loss: 0.6602\n",
      "Epoch 12/70\n",
      "84/84 - 10s - 119ms/step - accuracy: 0.8381 - loss: 0.4210 - val_accuracy: 0.7388 - val_loss: 0.6808\n",
      "Epoch 13/70\n",
      "84/84 - 10s - 118ms/step - accuracy: 0.8623 - loss: 0.3794 - val_accuracy: 0.7493 - val_loss: 0.6826\n",
      "Epoch 14/70\n",
      "84/84 - 10s - 118ms/step - accuracy: 0.8608 - loss: 0.3713 - val_accuracy: 0.7515 - val_loss: 0.6794\n",
      "Epoch 15/70\n",
      "84/84 - 10s - 118ms/step - accuracy: 0.8677 - loss: 0.3527 - val_accuracy: 0.7463 - val_loss: 0.6951\n",
      "Epoch 16/70\n",
      "84/84 - 10s - 118ms/step - accuracy: 0.8770 - loss: 0.3302 - val_accuracy: 0.7478 - val_loss: 0.6862\n",
      "Epoch 17/70\n",
      "84/84 - 10s - 118ms/step - accuracy: 0.8835 - loss: 0.3218 - val_accuracy: 0.7388 - val_loss: 0.7141\n",
      "Training time: 208.67 seconds\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 132ms/step - accuracy: 0.7553 - loss: 0.6247\n",
      "Xception - Test accuracy: 0.7601\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 101ms/step\n",
      "[4 4 1 ... 0 3 6]\n",
      "[4 4 1 ... 0 3 6]\n",
      "Accuracy: 0.7601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MobileNet\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf_no_top.h5\n",
      "\u001b[1m17225924/17225924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
      "Epoch 1/70\n",
      "84/84 - 25s - 301ms/step - accuracy: 0.4204 - loss: 1.5815 - val_accuracy: 0.6682 - val_loss: 0.9584\n",
      "Epoch 2/70\n",
      "84/84 - 4s - 45ms/step - accuracy: 0.6121 - loss: 1.0116 - val_accuracy: 0.7083 - val_loss: 0.7879\n",
      "Epoch 3/70\n",
      "84/84 - 4s - 44ms/step - accuracy: 0.6728 - loss: 0.8482 - val_accuracy: 0.7336 - val_loss: 0.7083\n",
      "Epoch 4/70\n",
      "84/84 - 4s - 44ms/step - accuracy: 0.7238 - loss: 0.7452 - val_accuracy: 0.7388 - val_loss: 0.6892\n",
      "Epoch 5/70\n",
      "84/84 - 4s - 43ms/step - accuracy: 0.7327 - loss: 0.6939 - val_accuracy: 0.7463 - val_loss: 0.6705\n",
      "Epoch 6/70\n",
      "84/84 - 4s - 44ms/step - accuracy: 0.7670 - loss: 0.6173 - val_accuracy: 0.7634 - val_loss: 0.6438\n",
      "Epoch 7/70\n",
      "84/84 - 4s - 44ms/step - accuracy: 0.7782 - loss: 0.5882 - val_accuracy: 0.7545 - val_loss: 0.6435\n",
      "Epoch 8/70\n",
      "84/84 - 4s - 44ms/step - accuracy: 0.7992 - loss: 0.5290 - val_accuracy: 0.7693 - val_loss: 0.6168\n",
      "Epoch 9/70\n",
      "84/84 - 4s - 45ms/step - accuracy: 0.8079 - loss: 0.5164 - val_accuracy: 0.7701 - val_loss: 0.6057\n",
      "Epoch 10/70\n",
      "84/84 - 4s - 44ms/step - accuracy: 0.8169 - loss: 0.4868 - val_accuracy: 0.7693 - val_loss: 0.6147\n",
      "Epoch 11/70\n",
      "84/84 - 4s - 44ms/step - accuracy: 0.8349 - loss: 0.4328 - val_accuracy: 0.7790 - val_loss: 0.5994\n",
      "Epoch 12/70\n",
      "84/84 - 4s - 43ms/step - accuracy: 0.8416 - loss: 0.4119 - val_accuracy: 0.7775 - val_loss: 0.6092\n",
      "Epoch 13/70\n",
      "84/84 - 4s - 44ms/step - accuracy: 0.8504 - loss: 0.3962 - val_accuracy: 0.7850 - val_loss: 0.6198\n",
      "Epoch 14/70\n",
      "84/84 - 4s - 44ms/step - accuracy: 0.8550 - loss: 0.3838 - val_accuracy: 0.7827 - val_loss: 0.6151\n",
      "Epoch 15/70\n",
      "84/84 - 4s - 44ms/step - accuracy: 0.8714 - loss: 0.3438 - val_accuracy: 0.7827 - val_loss: 0.6123\n",
      "Epoch 16/70\n",
      "84/84 - 4s - 44ms/step - accuracy: 0.8747 - loss: 0.3348 - val_accuracy: 0.7775 - val_loss: 0.6174\n",
      "Epoch 17/70\n",
      "84/84 - 4s - 44ms/step - accuracy: 0.8850 - loss: 0.3129 - val_accuracy: 0.7805 - val_loss: 0.6290\n",
      "Training time: 89.32 seconds\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 81ms/step - accuracy: 0.7802 - loss: 0.5680\n",
      "MobileNet - Test accuracy: 0.7929\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 55ms/step\n",
      "[4 4 1 ... 0 3 6]\n",
      "[4 4 5 ... 0 3 6]\n",
      "Accuracy: 0.7929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MobileNetV2\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
      "Epoch 1/70\n",
      "84/84 - 31s - 372ms/step - accuracy: 0.4768 - loss: 1.4437 - val_accuracy: 0.6778 - val_loss: 0.8943\n",
      "Epoch 2/70\n",
      "84/84 - 4s - 51ms/step - accuracy: 0.6538 - loss: 0.9200 - val_accuracy: 0.7240 - val_loss: 0.7297\n",
      "Epoch 3/70\n",
      "84/84 - 4s - 51ms/step - accuracy: 0.7059 - loss: 0.7713 - val_accuracy: 0.7217 - val_loss: 0.6973\n",
      "Epoch 4/70\n",
      "84/84 - 4s - 51ms/step - accuracy: 0.7391 - loss: 0.6730 - val_accuracy: 0.7381 - val_loss: 0.6930\n",
      "Epoch 5/70\n",
      "84/84 - 4s - 51ms/step - accuracy: 0.7694 - loss: 0.5938 - val_accuracy: 0.7463 - val_loss: 0.6480\n",
      "Epoch 6/70\n",
      "84/84 - 4s - 52ms/step - accuracy: 0.7927 - loss: 0.5460 - val_accuracy: 0.7515 - val_loss: 0.6279\n",
      "Epoch 7/70\n",
      "84/84 - 4s - 51ms/step - accuracy: 0.8117 - loss: 0.4967 - val_accuracy: 0.7626 - val_loss: 0.6209\n",
      "Epoch 8/70\n",
      "84/84 - 4s - 50ms/step - accuracy: 0.8310 - loss: 0.4544 - val_accuracy: 0.7552 - val_loss: 0.6219\n",
      "Epoch 9/70\n",
      "84/84 - 4s - 50ms/step - accuracy: 0.8385 - loss: 0.4294 - val_accuracy: 0.7619 - val_loss: 0.6466\n",
      "Epoch 10/70\n",
      "84/84 - 4s - 52ms/step - accuracy: 0.8517 - loss: 0.3909 - val_accuracy: 0.7746 - val_loss: 0.6024\n",
      "Epoch 11/70\n",
      "84/84 - 4s - 51ms/step - accuracy: 0.8593 - loss: 0.3783 - val_accuracy: 0.7597 - val_loss: 0.6246\n",
      "Epoch 12/70\n",
      "84/84 - 4s - 50ms/step - accuracy: 0.8781 - loss: 0.3327 - val_accuracy: 0.7545 - val_loss: 0.6220\n",
      "Epoch 13/70\n",
      "84/84 - 4s - 50ms/step - accuracy: 0.8749 - loss: 0.3323 - val_accuracy: 0.7701 - val_loss: 0.6265\n",
      "Epoch 14/70\n",
      "84/84 - 4s - 50ms/step - accuracy: 0.8867 - loss: 0.3052 - val_accuracy: 0.7656 - val_loss: 0.6447\n",
      "Epoch 15/70\n",
      "84/84 - 4s - 50ms/step - accuracy: 0.8939 - loss: 0.2821 - val_accuracy: 0.7664 - val_loss: 0.6259\n",
      "Epoch 16/70\n",
      "84/84 - 4s - 50ms/step - accuracy: 0.9023 - loss: 0.2620 - val_accuracy: 0.7656 - val_loss: 0.6443\n",
      "Training time: 99.91 seconds\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - accuracy: 0.7801 - loss: 0.5734\n",
      "MobileNetV2 - Test accuracy: 0.7940\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 84ms/step\n",
      "[4 4 1 ... 0 3 6]\n",
      "[9 4 1 ... 0 3 6]\n",
      "Accuracy: 0.7940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DenseNet121\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m29084464/29084464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
      "Epoch 1/70\n",
      "84/84 - 69s - 821ms/step - accuracy: 0.4275 - loss: 1.5962 - val_accuracy: 0.6801 - val_loss: 0.9429\n",
      "Epoch 2/70\n",
      "84/84 - 9s - 103ms/step - accuracy: 0.6415 - loss: 0.9703 - val_accuracy: 0.7299 - val_loss: 0.7370\n",
      "Epoch 3/70\n",
      "84/84 - 8s - 101ms/step - accuracy: 0.6966 - loss: 0.8144 - val_accuracy: 0.7574 - val_loss: 0.6533\n",
      "Epoch 4/70\n",
      "84/84 - 9s - 102ms/step - accuracy: 0.7262 - loss: 0.7227 - val_accuracy: 0.7567 - val_loss: 0.6204\n",
      "Epoch 5/70\n",
      "84/84 - 9s - 102ms/step - accuracy: 0.7554 - loss: 0.6559 - val_accuracy: 0.7686 - val_loss: 0.5872\n",
      "Epoch 6/70\n",
      "84/84 - 9s - 102ms/step - accuracy: 0.7752 - loss: 0.6078 - val_accuracy: 0.7723 - val_loss: 0.5694\n",
      "Epoch 7/70\n",
      "84/84 - 9s - 102ms/step - accuracy: 0.7809 - loss: 0.5838 - val_accuracy: 0.7760 - val_loss: 0.5638\n",
      "Epoch 8/70\n",
      "84/84 - 9s - 101ms/step - accuracy: 0.7934 - loss: 0.5544 - val_accuracy: 0.7790 - val_loss: 0.5599\n",
      "Epoch 9/70\n",
      "84/84 - 8s - 101ms/step - accuracy: 0.8035 - loss: 0.5135 - val_accuracy: 0.7768 - val_loss: 0.5583\n",
      "Epoch 10/70\n",
      "84/84 - 9s - 102ms/step - accuracy: 0.8025 - loss: 0.5125 - val_accuracy: 0.7820 - val_loss: 0.5312\n",
      "Epoch 11/70\n",
      "84/84 - 9s - 102ms/step - accuracy: 0.8252 - loss: 0.4671 - val_accuracy: 0.7976 - val_loss: 0.5161\n",
      "Epoch 12/70\n",
      "84/84 - 8s - 99ms/step - accuracy: 0.8306 - loss: 0.4550 - val_accuracy: 0.7887 - val_loss: 0.5401\n",
      "Epoch 13/70\n",
      "84/84 - 8s - 99ms/step - accuracy: 0.8336 - loss: 0.4416 - val_accuracy: 0.7984 - val_loss: 0.5208\n",
      "Epoch 14/70\n",
      "84/84 - 8s - 100ms/step - accuracy: 0.8418 - loss: 0.4230 - val_accuracy: 0.7939 - val_loss: 0.5242\n",
      "Epoch 15/70\n",
      "84/84 - 8s - 99ms/step - accuracy: 0.8427 - loss: 0.4102 - val_accuracy: 0.8058 - val_loss: 0.5267\n",
      "Epoch 16/70\n",
      "84/84 - 8s - 99ms/step - accuracy: 0.8487 - loss: 0.4047 - val_accuracy: 0.7909 - val_loss: 0.5321\n",
      "Epoch 17/70\n",
      "84/84 - 8s - 99ms/step - accuracy: 0.8519 - loss: 0.3882 - val_accuracy: 0.7939 - val_loss: 0.5215\n",
      "Training time: 209.64 seconds\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 258ms/step - accuracy: 0.8130 - loss: 0.4987\n",
      "DenseNet121 - Test accuracy: 0.8185\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 282ms/step\n",
      "[4 4 1 ... 0 3 6]\n",
      "[4 4 5 ... 0 3 6]\n",
      "Accuracy: 0.8185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VGG16\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n",
      "Epoch 1/70\n",
      "84/84 - 57s - 677ms/step - accuracy: 0.2233 - loss: 2.1138 - val_accuracy: 0.3564 - val_loss: 1.8637\n",
      "Epoch 2/70\n",
      "84/84 - 15s - 183ms/step - accuracy: 0.3406 - loss: 1.8131 - val_accuracy: 0.3899 - val_loss: 1.6667\n",
      "Epoch 3/70\n",
      "84/84 - 15s - 184ms/step - accuracy: 0.3881 - loss: 1.6687 - val_accuracy: 0.4702 - val_loss: 1.5263\n",
      "Epoch 4/70\n",
      "84/84 - 15s - 184ms/step - accuracy: 0.4294 - loss: 1.5560 - val_accuracy: 0.5134 - val_loss: 1.4374\n",
      "Epoch 5/70\n",
      "84/84 - 15s - 183ms/step - accuracy: 0.4591 - loss: 1.4806 - val_accuracy: 0.5342 - val_loss: 1.3596\n",
      "Epoch 6/70\n",
      "84/84 - 15s - 182ms/step - accuracy: 0.4871 - loss: 1.4101 - val_accuracy: 0.5379 - val_loss: 1.3188\n",
      "Epoch 7/70\n",
      "84/84 - 15s - 182ms/step - accuracy: 0.5055 - loss: 1.3673 - val_accuracy: 0.5655 - val_loss: 1.2666\n",
      "Epoch 8/70\n",
      "84/84 - 15s - 182ms/step - accuracy: 0.5189 - loss: 1.3271 - val_accuracy: 0.5744 - val_loss: 1.2413\n",
      "Epoch 9/70\n",
      "84/84 - 15s - 184ms/step - accuracy: 0.5226 - loss: 1.2831 - val_accuracy: 0.5960 - val_loss: 1.2010\n",
      "Epoch 10/70\n",
      "84/84 - 15s - 183ms/step - accuracy: 0.5395 - loss: 1.2574 - val_accuracy: 0.5826 - val_loss: 1.1827\n",
      "Epoch 11/70\n",
      "84/84 - 15s - 183ms/step - accuracy: 0.5554 - loss: 1.2292 - val_accuracy: 0.5960 - val_loss: 1.1619\n",
      "Epoch 12/70\n",
      "84/84 - 15s - 183ms/step - accuracy: 0.5602 - loss: 1.1982 - val_accuracy: 0.5975 - val_loss: 1.1465\n",
      "Epoch 13/70\n",
      "84/84 - 15s - 183ms/step - accuracy: 0.5695 - loss: 1.1866 - val_accuracy: 0.6116 - val_loss: 1.1113\n",
      "Epoch 14/70\n",
      "84/84 - 15s - 183ms/step - accuracy: 0.5781 - loss: 1.1599 - val_accuracy: 0.6131 - val_loss: 1.0950\n",
      "Epoch 15/70\n",
      "84/84 - 15s - 184ms/step - accuracy: 0.5844 - loss: 1.1327 - val_accuracy: 0.6086 - val_loss: 1.0883\n",
      "Epoch 16/70\n",
      "84/84 - 15s - 182ms/step - accuracy: 0.5905 - loss: 1.1146 - val_accuracy: 0.5990 - val_loss: 1.0887\n",
      "Epoch 17/70\n",
      "84/84 - 15s - 183ms/step - accuracy: 0.5928 - loss: 1.1064 - val_accuracy: 0.6176 - val_loss: 1.0777\n",
      "Epoch 18/70\n",
      "84/84 - 15s - 183ms/step - accuracy: 0.6041 - loss: 1.0848 - val_accuracy: 0.6146 - val_loss: 1.0566\n",
      "Epoch 19/70\n",
      "84/84 - 15s - 183ms/step - accuracy: 0.6114 - loss: 1.0786 - val_accuracy: 0.6362 - val_loss: 1.0461\n",
      "Epoch 20/70\n",
      "84/84 - 15s - 183ms/step - accuracy: 0.6142 - loss: 1.0623 - val_accuracy: 0.6324 - val_loss: 1.0645\n",
      "Epoch 21/70\n",
      "84/84 - 15s - 183ms/step - accuracy: 0.6157 - loss: 1.0494 - val_accuracy: 0.6257 - val_loss: 1.0411\n",
      "Epoch 22/70\n",
      "84/84 - 15s - 183ms/step - accuracy: 0.6240 - loss: 1.0336 - val_accuracy: 0.6243 - val_loss: 1.0152\n",
      "Epoch 23/70\n",
      "84/84 - 15s - 183ms/step - accuracy: 0.6270 - loss: 1.0213 - val_accuracy: 0.6295 - val_loss: 1.0109\n",
      "Epoch 24/70\n",
      "84/84 - 15s - 183ms/step - accuracy: 0.6334 - loss: 1.0115 - val_accuracy: 0.6481 - val_loss: 0.9982\n",
      "Epoch 25/70\n",
      "84/84 - 15s - 183ms/step - accuracy: 0.6307 - loss: 0.9991 - val_accuracy: 0.6548 - val_loss: 0.9973\n",
      "Epoch 26/70\n",
      "84/84 - 15s - 183ms/step - accuracy: 0.6458 - loss: 0.9790 - val_accuracy: 0.6488 - val_loss: 0.9856\n",
      "Epoch 27/70\n",
      "84/84 - 15s - 183ms/step - accuracy: 0.6404 - loss: 0.9807 - val_accuracy: 0.6436 - val_loss: 0.9957\n",
      "Epoch 28/70\n",
      "84/84 - 15s - 182ms/step - accuracy: 0.6492 - loss: 0.9587 - val_accuracy: 0.6384 - val_loss: 1.0040\n",
      "Epoch 29/70\n",
      "84/84 - 15s - 183ms/step - accuracy: 0.6538 - loss: 0.9538 - val_accuracy: 0.6458 - val_loss: 0.9819\n",
      "Epoch 30/70\n",
      "84/84 - 15s - 183ms/step - accuracy: 0.6529 - loss: 0.9436 - val_accuracy: 0.6667 - val_loss: 0.9804\n",
      "Epoch 31/70\n",
      "84/84 - 15s - 183ms/step - accuracy: 0.6583 - loss: 0.9446 - val_accuracy: 0.6577 - val_loss: 0.9688\n",
      "Epoch 32/70\n",
      "84/84 - 15s - 182ms/step - accuracy: 0.6663 - loss: 0.9245 - val_accuracy: 0.6555 - val_loss: 0.9733\n",
      "Epoch 33/70\n",
      "84/84 - 15s - 182ms/step - accuracy: 0.6587 - loss: 0.9251 - val_accuracy: 0.6548 - val_loss: 0.9689\n",
      "Epoch 34/70\n",
      "84/84 - 15s - 183ms/step - accuracy: 0.6771 - loss: 0.9051 - val_accuracy: 0.6607 - val_loss: 0.9529\n",
      "Epoch 35/70\n",
      "84/84 - 15s - 183ms/step - accuracy: 0.6736 - loss: 0.8897 - val_accuracy: 0.6592 - val_loss: 0.9482\n",
      "Epoch 36/70\n",
      "84/84 - 15s - 182ms/step - accuracy: 0.6762 - loss: 0.8913 - val_accuracy: 0.6429 - val_loss: 0.9702\n",
      "Epoch 37/70\n",
      "84/84 - 15s - 182ms/step - accuracy: 0.6784 - loss: 0.8863 - val_accuracy: 0.6481 - val_loss: 0.9623\n",
      "Epoch 38/70\n",
      "84/84 - 15s - 182ms/step - accuracy: 0.6745 - loss: 0.8756 - val_accuracy: 0.6585 - val_loss: 0.9513\n",
      "Epoch 39/70\n",
      "84/84 - 15s - 183ms/step - accuracy: 0.6696 - loss: 0.8881 - val_accuracy: 0.6548 - val_loss: 0.9468\n",
      "Epoch 40/70\n",
      "84/84 - 15s - 183ms/step - accuracy: 0.6791 - loss: 0.8660 - val_accuracy: 0.6600 - val_loss: 0.9426\n",
      "Epoch 41/70\n",
      "84/84 - 15s - 183ms/step - accuracy: 0.6821 - loss: 0.8680 - val_accuracy: 0.6466 - val_loss: 0.9480\n",
      "Epoch 42/70\n",
      "84/84 - 15s - 183ms/step - accuracy: 0.6998 - loss: 0.8415 - val_accuracy: 0.6540 - val_loss: 0.9562\n",
      "Epoch 43/70\n",
      "84/84 - 15s - 183ms/step - accuracy: 0.6868 - loss: 0.8494 - val_accuracy: 0.6607 - val_loss: 0.9501\n",
      "Epoch 44/70\n",
      "84/84 - 15s - 183ms/step - accuracy: 0.6933 - loss: 0.8371 - val_accuracy: 0.6644 - val_loss: 0.9483\n",
      "Epoch 45/70\n",
      "84/84 - 15s - 182ms/step - accuracy: 0.6944 - loss: 0.8418 - val_accuracy: 0.6577 - val_loss: 0.9406\n",
      "Epoch 46/70\n",
      "84/84 - 15s - 183ms/step - accuracy: 0.7030 - loss: 0.8257 - val_accuracy: 0.6562 - val_loss: 0.9457\n",
      "Epoch 47/70\n",
      "84/84 - 15s - 182ms/step - accuracy: 0.6991 - loss: 0.8167 - val_accuracy: 0.6615 - val_loss: 0.9276\n",
      "Epoch 48/70\n",
      "84/84 - 15s - 182ms/step - accuracy: 0.6991 - loss: 0.8226 - val_accuracy: 0.6622 - val_loss: 0.9330\n",
      "Epoch 49/70\n",
      "84/84 - 15s - 183ms/step - accuracy: 0.6989 - loss: 0.8174 - val_accuracy: 0.6622 - val_loss: 0.9248\n",
      "Epoch 50/70\n",
      "84/84 - 15s - 182ms/step - accuracy: 0.7095 - loss: 0.8058 - val_accuracy: 0.6622 - val_loss: 0.9290\n",
      "Epoch 51/70\n",
      "84/84 - 15s - 182ms/step - accuracy: 0.7085 - loss: 0.7893 - val_accuracy: 0.6525 - val_loss: 0.9348\n",
      "Epoch 52/70\n",
      "84/84 - 15s - 182ms/step - accuracy: 0.7098 - loss: 0.7958 - val_accuracy: 0.6585 - val_loss: 0.9358\n",
      "Epoch 53/70\n",
      "84/84 - 15s - 182ms/step - accuracy: 0.7102 - loss: 0.7949 - val_accuracy: 0.6510 - val_loss: 0.9351\n",
      "Epoch 54/70\n",
      "84/84 - 15s - 182ms/step - accuracy: 0.7234 - loss: 0.7674 - val_accuracy: 0.6644 - val_loss: 0.9285\n",
      "Epoch 55/70\n",
      "84/84 - 15s - 182ms/step - accuracy: 0.7218 - loss: 0.7652 - val_accuracy: 0.6585 - val_loss: 0.9318\n",
      "Training time: 891.86 seconds\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 183ms/step - accuracy: 0.6647 - loss: 0.9063\n",
      "VGG16 - Test accuracy: 0.6750\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step\n",
      "[4 4 1 ... 0 3 6]\n",
      "[4 4 4 ... 0 3 6]\n",
      "Accuracy: 0.6750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 78ms/step - accuracy: 0.1542 - loss: 2.3682 - val_accuracy: 0.3222 - val_loss: 1.8882\n",
      "Epoch 2/70\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - accuracy: 0.2971 - loss: 1.8594 - val_accuracy: 0.4033 - val_loss: 1.6009\n",
      "Epoch 3/70\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - accuracy: 0.4354 - loss: 1.5446 - val_accuracy: 0.4807 - val_loss: 1.4091\n",
      "Epoch 4/70\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - accuracy: 0.5061 - loss: 1.3607 - val_accuracy: 0.5097 - val_loss: 1.3842\n",
      "Epoch 5/70\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - accuracy: 0.5899 - loss: 1.1466 - val_accuracy: 0.5260 - val_loss: 1.3313\n",
      "Epoch 6/70\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - accuracy: 0.6790 - loss: 0.9180 - val_accuracy: 0.5365 - val_loss: 1.3655\n",
      "Epoch 7/70\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - accuracy: 0.7370 - loss: 0.6997 - val_accuracy: 0.5208 - val_loss: 1.5140\n",
      "Epoch 8/70\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - accuracy: 0.8019 - loss: 0.5591 - val_accuracy: 0.5141 - val_loss: 1.6644\n",
      "Epoch 9/70\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - accuracy: 0.8233 - loss: 0.5119 - val_accuracy: 0.4978 - val_loss: 1.8656\n",
      "Epoch 10/70\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - accuracy: 0.8549 - loss: 0.4113 - val_accuracy: 0.5045 - val_loss: 1.8787\n",
      "Epoch 11/70\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - accuracy: 0.8827 - loss: 0.3467 - val_accuracy: 0.5015 - val_loss: 2.2294\n",
      "Training time: 91.11 seconds\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.5347 - loss: 1.2579\n",
      "Test accuracy: 0.5512\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Model  Test Accuracy  Training Time (s)\n",
      "0  InceptionV3       0.738690         127.865819\n",
      "1     Xception       0.760119         208.671374\n",
      "2    MobileNet       0.792857          89.317813\n",
      "3  MobileNetV2       0.794048          99.906089\n",
      "4  DenseNet121       0.818452         209.636113\n",
      "5        VGG16       0.675000         891.858847\n",
      "6           my       0.551190          91.106546\n"
     ]
    }
   ],
   "source": [
    "param = \"bez_meta\"\n",
    "\n",
    "results = []\n",
    "\n",
    "for model_class, name in zip(model_classes, model_names):\n",
    "    print(f\"\\n{name}\")\n",
    "\n",
    "    base_model = model_class(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    base_model.trainable = False  \n",
    "\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(len(le.classes_), activation='softmax') \n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    start_time = time.time()\n",
    "    history = model.fit(\n",
    "        X_img_train, y_train_enc,\n",
    "        epochs=70,\n",
    "        batch_size=64,\n",
    "        validation_split=0.2,\n",
    "        verbose=2,\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    print(f\"Training time: {training_time:.2f} seconds\")\n",
    "\n",
    "    loss, acc = model.evaluate(X_img_test, y_test_enc)\n",
    "    print(f\"{name} - Test accuracy: {acc:.4f}\")\n",
    "\n",
    "    y_prob = model.predict(X_img_test)\n",
    "    y_pred = np.argmax(y_prob, axis=1)\n",
    "    y_true = np.argmax(y_test_enc, axis=1)\n",
    "    print(y_true)\n",
    "    print(y_pred)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    with open(f\"/content/drive/MyDrive/Master - A/3_fig/{param}_{name}_results.txt\", \"w\") as f:\n",
    "        f.write(f\"Model: {name}\\n\")\n",
    "        f.write(f\"Training time: {training_time:.2f} sec\\n\")\n",
    "        f.write(f\"Accuracy: {acc:.4f}\\n\\n\")\n",
    "        f.write(\"Classification Report:\\n\")\n",
    "\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"/content/drive/MyDrive/Master - A/3_fig/{param}_{name}_matrix.png\")\n",
    "    plt.close()\n",
    "\n",
    "    model.save(f'/content/drive/MyDrive/Master - A/3_fig/{param}_{name}_model.h5')\n",
    "\n",
    "\n",
    "    file_path = f\"/content/drive/MyDrive/Master - A/3_fig/{param}_{name}_history.pkl\"\n",
    "    with open(file_path, 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epochs', fontsize=18)\n",
    "    plt.ylabel('Loss', fontsize=18)\n",
    "    plt.xticks(fontsize=18)\n",
    "    plt.yticks(fontsize=18)\n",
    "    plt.tight_layout()\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"/content/drive/MyDrive/Master - A/3_fig/{param}_{name}_train_val_loss.png\")\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.xlabel('Epochs', fontsize=18)\n",
    "    plt.ylabel('Accuracy', fontsize=18)\n",
    "    plt.xticks(fontsize=18)\n",
    "    plt.yticks(fontsize=18)\n",
    "    plt.tight_layout()\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"/content/drive/MyDrive/Master - A/3_fig/{param}_{name}_train_val_accuracy.png\")\n",
    "    plt.close()\n",
    "\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Test Accuracy': acc,\n",
    "          'Training Time (s)': training_time\n",
    "      })\n",
    "\n",
    "model = my_cnn(num_classes=len(le.classes_))\n",
    "name = \"my\"\n",
    "\n",
    "start_time = time.time()\n",
    "history = model.fit(X_img_train, y_train_enc, epochs=70, batch_size=32,\n",
    "                    validation_split=0.2, verbose=1, callbacks=[early_stopping])\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "print(f\"Training time: {training_time:.2f} seconds\")\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_img_test, y_test_enc)\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")\n",
    "\n",
    "y_prob = model.predict(X_img_test)\n",
    "y_pred = np.argmax(y_prob, axis=1)\n",
    "y_true = np.argmax(y_test_enc, axis=1)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"/content/drive/MyDrive/Master - A/3_fig/{param}_{name}_matrix.png\")\n",
    "plt.close()\n",
    "\n",
    "model.save(f'/content/drive/MyDrive/Master - A/3_fig/{param}_{name}_model.h5')\n",
    "\n",
    "file_path = f\"/content/drive/MyDrive/Master - A/3_fig/{param}_{name}_history.pkl\"\n",
    "with open(file_path, 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs', fontsize=18)\n",
    "plt.ylabel('Loss', fontsize=18)\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.savefig(f\"/content/drive/MyDrive/Master - A/3_fig/{param}_{name}_train_val_loss.png\")\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs', fontsize=18)\n",
    "plt.ylabel('Accuracy', fontsize=18)\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.savefig(f\"/content/drive/MyDrive/Master - A/3_fig/{param}_{name}_train_val_accuracy.png\")\n",
    "plt.close()\n",
    "\n",
    "results.append({\n",
    "    'Model': name,\n",
    "    'Test Accuracy': test_acc,\n",
    "    'Training Time (s)': training_time\n",
    "})\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(f'/content/drive/MyDrive/Master - A/3_fig/{param}_model_training_results.csv', index=False)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc85b26",
   "metadata": {
    "id": "7fc85b26"
   },
   "source": [
    "### Z meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BZYv_uj6imxZ",
   "metadata": {
    "id": "BZYv_uj6imxZ"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Concatenate, Dropout\n",
    "\n",
    "def cnn_sim_combined(x_train_img, x_test_img, x_train_meta, x_test_meta, y_train, y_test, param):\n",
    "    results = []\n",
    "\n",
    "    for model_class, name in zip(model_classes, model_names):\n",
    "        print(f\"\\n{name}\")\n",
    "\n",
    "        base_model = model_class(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "        base_model.trainable = False\n",
    "\n",
    "        image_input = Input(shape=(IMG_SIZE, IMG_SIZE, 3), name='image_input')\n",
    "        meta_input = Input(shape=(x_train_meta.shape[1],), name='meta_input')\n",
    "\n",
    "        x = base_model(image_input, training=False)\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dense(128, activation='relu')(x)\n",
    "\n",
    "        m = Dense(64, activation='relu')(meta_input)\n",
    "\n",
    "        combined = Concatenate()([x, m])\n",
    "        combined = Dense(128, activation='relu')(combined)\n",
    "        combined = Dropout(0.5)(combined)\n",
    "        output = Dense(len(le.classes_), activation='softmax')(combined)\n",
    "\n",
    "        model = Model(inputs=[image_input, meta_input], outputs=output)\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        start_time = time.time()\n",
    "        history = model.fit(\n",
    "            [x_train_img, x_train_meta], y_train,\n",
    "            epochs=70,\n",
    "            batch_size=64,\n",
    "            validation_split=0.2,\n",
    "            verbose=2,\n",
    "            callbacks=[early_stopping]\n",
    "        )\n",
    "        training_time = time.time() - start_time\n",
    "\n",
    "        loss, acc = model.evaluate([x_test_img, x_test_meta], y_test)\n",
    "        print(f\"{name} - Test accuracy: {acc:.4f}\")\n",
    "\n",
    "        y_prob = model.predict([x_test_img, x_test_meta])\n",
    "        y_pred = np.argmax(y_prob, axis=1)\n",
    "        y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(y_true, y_pred))\n",
    "\n",
    "        with open(f\"/content/drive/MyDrive/Master - A/3_fig/{param}_{name}_results.txt\", \"w\") as f:\n",
    "            f.write(f\"Model: {name}\\n\")\n",
    "            f.write(f\"Training time: {training_time:.2f} sec\\n\")\n",
    "            f.write(f\"Accuracy: {acc:.4f}\\n\\n\")\n",
    "            f.write(\"Classification Report:\\n\")\n",
    "            f.write(classification_report(y_true, y_pred))\n",
    "\n",
    "        conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"/content/drive/MyDrive/Master - A/3_fig/{param}_{name}_matrix.png\")\n",
    "        plt.close()\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(history.history['loss'], label='Train Loss')\n",
    "        plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"/content/drive/MyDrive/Master - A/3_fig/{param}_{name}_train_val_loss.png\")\n",
    "        plt.close()\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "        plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"/content/drive/MyDrive/Master - A/3_fig/{param}_{name}_train_val_accuracy.png\")\n",
    "        plt.close()\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_prob[:, 1]) if y_prob.shape[1] == 2 else (None, None, None)\n",
    "        if fpr is not None:\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})', lw=2)\n",
    "            plt.plot([0, 1], [0, 1], 'k--')\n",
    "            plt.xlabel('False Positive Rate')\n",
    "            plt.ylabel('True Positive Rate')\n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"/content/drive/MyDrive/Master - A/3_fig/{param}_{name}_roc_curve.png\")\n",
    "            plt.close()\n",
    "\n",
    "        model.save(f'/content/drive/MyDrive/Master - A/3_fig/{param}_{name}_model.h5')\n",
    "\n",
    "        results.append({\n",
    "            'Model': name,\n",
    "            'Test Accuracy': acc,\n",
    "            'Training Time (s)': training_time\n",
    "        })\n",
    "\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(f'/content/drive/MyDrive/Master - A/3_fig/{param}_model_training_results.csv', index=False)\n",
    "    print(results_df)\n",
    "\n",
    "\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Concatenate, Dropout\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rwyLvBK_1iGg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1749156271913,
     "user": {
      "displayName": "Aleksandra Hendrysiak",
      "userId": "02783590481816071264"
     },
     "user_tz": -120
    },
    "id": "rwyLvBK_1iGg",
    "outputId": "083f3b6e-4acf-409c-ac34-e1cecc9eac2b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6717, 224, 224, 3),\n",
       " (1680, 224, 224, 3),\n",
       " (1680, 2),\n",
       " (6717, 2),\n",
       " (6717, 10),\n",
       " (1680, 10))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_img_train.shape, X_img_test.shape, X_meta_test.shape, X_meta_train.shape, y_train_enc.shape, y_test_enc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HLqpN_c6jFHc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1366411,
     "status": "ok",
     "timestamp": 1749157911549,
     "user": {
      "displayName": "Aleksandra Hendrysiak",
      "userId": "02783590481816071264"
     },
     "user_tz": -120
    },
    "id": "HLqpN_c6jFHc",
    "outputId": "c5840af1-edb5-4586-aba1-38371ad3c056"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "InceptionV3\n",
      "Epoch 1/70\n",
      "84/84 - 34s - 405ms/step - accuracy: 0.4057 - loss: 1.6776 - val_accuracy: 0.6280 - val_loss: 1.0266\n",
      "Epoch 2/70\n",
      "84/84 - 5s - 61ms/step - accuracy: 0.5924 - loss: 1.0740 - val_accuracy: 0.6585 - val_loss: 0.8833\n",
      "Epoch 3/70\n",
      "84/84 - 5s - 61ms/step - accuracy: 0.6523 - loss: 0.9052 - val_accuracy: 0.7001 - val_loss: 0.7963\n",
      "Epoch 4/70\n",
      "84/84 - 5s - 61ms/step - accuracy: 0.7059 - loss: 0.7682 - val_accuracy: 0.7240 - val_loss: 0.7281\n",
      "Epoch 5/70\n",
      "84/84 - 5s - 59ms/step - accuracy: 0.7346 - loss: 0.6938 - val_accuracy: 0.7202 - val_loss: 0.7464\n",
      "Epoch 6/70\n",
      "84/84 - 5s - 59ms/step - accuracy: 0.7614 - loss: 0.6222 - val_accuracy: 0.7188 - val_loss: 0.7317\n",
      "Epoch 7/70\n",
      "84/84 - 5s - 60ms/step - accuracy: 0.7698 - loss: 0.5845 - val_accuracy: 0.7314 - val_loss: 0.7055\n",
      "Epoch 8/70\n",
      "84/84 - 5s - 59ms/step - accuracy: 0.7936 - loss: 0.5466 - val_accuracy: 0.7351 - val_loss: 0.7198\n",
      "Epoch 9/70\n",
      "84/84 - 5s - 59ms/step - accuracy: 0.8174 - loss: 0.4754 - val_accuracy: 0.7269 - val_loss: 0.7255\n",
      "Epoch 10/70\n",
      "84/84 - 5s - 59ms/step - accuracy: 0.8269 - loss: 0.4548 - val_accuracy: 0.7143 - val_loss: 0.7696\n",
      "Epoch 11/70\n",
      "84/84 - 5s - 59ms/step - accuracy: 0.8304 - loss: 0.4392 - val_accuracy: 0.7351 - val_loss: 0.7469\n",
      "Epoch 12/70\n",
      "84/84 - 5s - 59ms/step - accuracy: 0.8407 - loss: 0.4123 - val_accuracy: 0.7321 - val_loss: 0.7824\n",
      "Epoch 13/70\n",
      "84/84 - 5s - 59ms/step - accuracy: 0.8567 - loss: 0.3815 - val_accuracy: 0.7135 - val_loss: 0.8241\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 0.7462 - loss: 0.6385\n",
      "InceptionV3 - Test accuracy: 0.7560\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 132ms/step\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91       192\n",
      "           1       0.84      0.80      0.82       158\n",
      "           2       0.86      0.88      0.87       161\n",
      "           3       0.79      0.75      0.77       149\n",
      "           4       0.85      0.74      0.79       170\n",
      "           5       0.65      0.80      0.72       164\n",
      "           6       0.77      0.59      0.67       181\n",
      "           7       0.65      0.84      0.73       184\n",
      "           8       0.62      0.72      0.67       169\n",
      "           9       0.70      0.49      0.58       152\n",
      "\n",
      "    accuracy                           0.76      1680\n",
      "   macro avg       0.76      0.75      0.75      1680\n",
      "weighted avg       0.76      0.76      0.75      1680\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Xception\n",
      "Epoch 1/70\n",
      "84/84 - 26s - 310ms/step - accuracy: 0.4541 - loss: 1.4850 - val_accuracy: 0.6548 - val_loss: 0.8977\n",
      "Epoch 2/70\n",
      "84/84 - 10s - 119ms/step - accuracy: 0.6348 - loss: 0.9157 - val_accuracy: 0.7031 - val_loss: 0.7474\n",
      "Epoch 3/70\n",
      "84/84 - 10s - 120ms/step - accuracy: 0.7061 - loss: 0.7618 - val_accuracy: 0.7113 - val_loss: 0.7240\n",
      "Epoch 4/70\n",
      "84/84 - 10s - 119ms/step - accuracy: 0.7366 - loss: 0.6657 - val_accuracy: 0.7158 - val_loss: 0.7016\n",
      "Epoch 5/70\n",
      "84/84 - 10s - 120ms/step - accuracy: 0.7724 - loss: 0.5967 - val_accuracy: 0.7426 - val_loss: 0.6645\n",
      "Epoch 6/70\n",
      "84/84 - 10s - 119ms/step - accuracy: 0.7919 - loss: 0.5319 - val_accuracy: 0.7336 - val_loss: 0.6536\n",
      "Epoch 7/70\n",
      "84/84 - 10s - 119ms/step - accuracy: 0.8042 - loss: 0.4879 - val_accuracy: 0.7448 - val_loss: 0.6289\n",
      "Epoch 8/70\n",
      "84/84 - 10s - 118ms/step - accuracy: 0.8358 - loss: 0.4267 - val_accuracy: 0.7426 - val_loss: 0.6732\n",
      "Epoch 9/70\n",
      "84/84 - 10s - 119ms/step - accuracy: 0.8487 - loss: 0.3899 - val_accuracy: 0.7440 - val_loss: 0.6555\n",
      "Epoch 10/70\n",
      "84/84 - 10s - 119ms/step - accuracy: 0.8628 - loss: 0.3497 - val_accuracy: 0.7336 - val_loss: 0.6875\n",
      "Epoch 11/70\n",
      "84/84 - 10s - 119ms/step - accuracy: 0.8824 - loss: 0.3160 - val_accuracy: 0.7478 - val_loss: 0.6805\n",
      "Epoch 12/70\n",
      "84/84 - 10s - 118ms/step - accuracy: 0.8913 - loss: 0.2897 - val_accuracy: 0.7567 - val_loss: 0.6836\n",
      "Epoch 13/70\n",
      "84/84 - 10s - 119ms/step - accuracy: 0.9021 - loss: 0.2594 - val_accuracy: 0.7500 - val_loss: 0.7171\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 80ms/step - accuracy: 0.7710 - loss: 0.5831\n",
      "Xception - Test accuracy: 0.7768\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 99ms/step\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.87      0.92       192\n",
      "           1       0.76      0.87      0.81       158\n",
      "           2       0.87      0.94      0.91       161\n",
      "           3       0.86      0.81      0.84       149\n",
      "           4       0.89      0.84      0.86       170\n",
      "           5       0.75      0.77      0.76       164\n",
      "           6       0.75      0.66      0.70       181\n",
      "           7       0.67      0.79      0.72       184\n",
      "           8       0.68      0.52      0.59       169\n",
      "           9       0.59      0.70      0.64       152\n",
      "\n",
      "    accuracy                           0.78      1680\n",
      "   macro avg       0.78      0.78      0.78      1680\n",
      "weighted avg       0.78      0.78      0.78      1680\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MobileNet\n",
      "Epoch 1/70\n",
      "84/84 - 16s - 191ms/step - accuracy: 0.4044 - loss: 1.6576 - val_accuracy: 0.6481 - val_loss: 0.9479\n",
      "Epoch 2/70\n",
      "84/84 - 4s - 44ms/step - accuracy: 0.6200 - loss: 0.9813 - val_accuracy: 0.7054 - val_loss: 0.7631\n",
      "Epoch 3/70\n",
      "84/84 - 4s - 44ms/step - accuracy: 0.7020 - loss: 0.7901 - val_accuracy: 0.7307 - val_loss: 0.6732\n",
      "Epoch 4/70\n",
      "84/84 - 4s - 44ms/step - accuracy: 0.7381 - loss: 0.6816 - val_accuracy: 0.7381 - val_loss: 0.6426\n",
      "Epoch 5/70\n",
      "84/84 - 4s - 43ms/step - accuracy: 0.7735 - loss: 0.5859 - val_accuracy: 0.7619 - val_loss: 0.6118\n",
      "Epoch 6/70\n",
      "84/84 - 4s - 44ms/step - accuracy: 0.7958 - loss: 0.5290 - val_accuracy: 0.7783 - val_loss: 0.5807\n",
      "Epoch 7/70\n",
      "84/84 - 4s - 43ms/step - accuracy: 0.8280 - loss: 0.4611 - val_accuracy: 0.7671 - val_loss: 0.5906\n",
      "Epoch 8/70\n",
      "84/84 - 4s - 43ms/step - accuracy: 0.8411 - loss: 0.4206 - val_accuracy: 0.7641 - val_loss: 0.5934\n",
      "Epoch 9/70\n",
      "84/84 - 4s - 43ms/step - accuracy: 0.8519 - loss: 0.3882 - val_accuracy: 0.7701 - val_loss: 0.5882\n",
      "Epoch 10/70\n",
      "84/84 - 4s - 43ms/step - accuracy: 0.8617 - loss: 0.3595 - val_accuracy: 0.7731 - val_loss: 0.5963\n",
      "Epoch 11/70\n",
      "84/84 - 4s - 44ms/step - accuracy: 0.8846 - loss: 0.3102 - val_accuracy: 0.7775 - val_loss: 0.5990\n",
      "Epoch 12/70\n",
      "84/84 - 4s - 43ms/step - accuracy: 0.8969 - loss: 0.2766 - val_accuracy: 0.7790 - val_loss: 0.6553\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 45ms/step - accuracy: 0.7532 - loss: 0.5742\n",
      "MobileNet - Test accuracy: 0.7714\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 55ms/step\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91       192\n",
      "           1       0.83      0.81      0.82       158\n",
      "           2       0.89      0.88      0.88       161\n",
      "           3       0.81      0.81      0.81       149\n",
      "           4       0.91      0.74      0.82       170\n",
      "           5       0.64      0.85      0.73       164\n",
      "           6       0.80      0.59      0.68       181\n",
      "           7       0.68      0.84      0.75       184\n",
      "           8       0.63      0.71      0.67       169\n",
      "           9       0.70      0.60      0.65       152\n",
      "\n",
      "    accuracy                           0.77      1680\n",
      "   macro avg       0.78      0.77      0.77      1680\n",
      "weighted avg       0.78      0.77      0.77      1680\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MobileNetV2\n",
      "Epoch 1/70\n",
      "84/84 - 22s - 261ms/step - accuracy: 0.4673 - loss: 1.4655 - val_accuracy: 0.6927 - val_loss: 0.8334\n",
      "Epoch 2/70\n",
      "84/84 - 4s - 51ms/step - accuracy: 0.6588 - loss: 0.8777 - val_accuracy: 0.7135 - val_loss: 0.7338\n",
      "Epoch 3/70\n",
      "84/84 - 4s - 51ms/step - accuracy: 0.7316 - loss: 0.6887 - val_accuracy: 0.7433 - val_loss: 0.6460\n",
      "Epoch 4/70\n",
      "84/84 - 4s - 51ms/step - accuracy: 0.7783 - loss: 0.5753 - val_accuracy: 0.7567 - val_loss: 0.6105\n",
      "Epoch 5/70\n",
      "84/84 - 4s - 49ms/step - accuracy: 0.8092 - loss: 0.5036 - val_accuracy: 0.7463 - val_loss: 0.6356\n",
      "Epoch 6/70\n",
      "84/84 - 4s - 50ms/step - accuracy: 0.8278 - loss: 0.4477 - val_accuracy: 0.7641 - val_loss: 0.6185\n",
      "Epoch 7/70\n",
      "84/84 - 4s - 51ms/step - accuracy: 0.8593 - loss: 0.3695 - val_accuracy: 0.7641 - val_loss: 0.5987\n",
      "Epoch 8/70\n",
      "84/84 - 4s - 50ms/step - accuracy: 0.8612 - loss: 0.3603 - val_accuracy: 0.7560 - val_loss: 0.6365\n",
      "Epoch 9/70\n",
      "84/84 - 4s - 50ms/step - accuracy: 0.8863 - loss: 0.2999 - val_accuracy: 0.7619 - val_loss: 0.6821\n",
      "Epoch 10/70\n",
      "84/84 - 4s - 49ms/step - accuracy: 0.8973 - loss: 0.2659 - val_accuracy: 0.7723 - val_loss: 0.6422\n",
      "Epoch 11/70\n",
      "84/84 - 4s - 49ms/step - accuracy: 0.9092 - loss: 0.2399 - val_accuracy: 0.7768 - val_loss: 0.6538\n",
      "Epoch 12/70\n",
      "84/84 - 4s - 50ms/step - accuracy: 0.9211 - loss: 0.2083 - val_accuracy: 0.7574 - val_loss: 0.7489\n",
      "Epoch 13/70\n",
      "84/84 - 4s - 49ms/step - accuracy: 0.9220 - loss: 0.2088 - val_accuracy: 0.7716 - val_loss: 0.6963\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 64ms/step - accuracy: 0.7569 - loss: 0.5878\n",
      "MobileNetV2 - Test accuracy: 0.7869\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 86ms/step\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.92       192\n",
      "           1       0.76      0.82      0.79       158\n",
      "           2       0.97      0.91      0.94       161\n",
      "           3       0.81      0.96      0.88       149\n",
      "           4       0.83      0.82      0.82       170\n",
      "           5       0.86      0.80      0.83       164\n",
      "           6       0.70      0.80      0.75       181\n",
      "           7       0.82      0.62      0.71       184\n",
      "           8       0.66      0.56      0.61       169\n",
      "           9       0.56      0.69      0.62       152\n",
      "\n",
      "    accuracy                           0.79      1680\n",
      "   macro avg       0.79      0.79      0.79      1680\n",
      "weighted avg       0.79      0.79      0.79      1680\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DenseNet121\n",
      "Epoch 1/70\n",
      "84/84 - 58s - 694ms/step - accuracy: 0.3921 - loss: 1.6989 - val_accuracy: 0.6436 - val_loss: 0.9616\n",
      "Epoch 2/70\n",
      "84/84 - 8s - 100ms/step - accuracy: 0.6118 - loss: 0.9834 - val_accuracy: 0.7180 - val_loss: 0.7137\n",
      "Epoch 3/70\n",
      "84/84 - 8s - 100ms/step - accuracy: 0.6953 - loss: 0.7704 - val_accuracy: 0.7448 - val_loss: 0.6503\n",
      "Epoch 4/70\n",
      "84/84 - 9s - 102ms/step - accuracy: 0.7433 - loss: 0.6671 - val_accuracy: 0.7783 - val_loss: 0.5627\n",
      "Epoch 5/70\n",
      "84/84 - 8s - 99ms/step - accuracy: 0.7748 - loss: 0.5804 - val_accuracy: 0.7589 - val_loss: 0.5711\n",
      "Epoch 6/70\n",
      "84/84 - 9s - 102ms/step - accuracy: 0.7869 - loss: 0.5439 - val_accuracy: 0.7783 - val_loss: 0.5405\n",
      "Epoch 7/70\n",
      "84/84 - 8s - 101ms/step - accuracy: 0.8061 - loss: 0.4895 - val_accuracy: 0.7820 - val_loss: 0.5301\n",
      "Epoch 8/70\n",
      "84/84 - 8s - 99ms/step - accuracy: 0.8172 - loss: 0.4666 - val_accuracy: 0.7708 - val_loss: 0.5617\n",
      "Epoch 9/70\n",
      "84/84 - 8s - 98ms/step - accuracy: 0.8331 - loss: 0.4399 - val_accuracy: 0.7909 - val_loss: 0.5313\n",
      "Epoch 10/70\n",
      "84/84 - 8s - 101ms/step - accuracy: 0.8364 - loss: 0.4128 - val_accuracy: 0.7939 - val_loss: 0.5127\n",
      "Epoch 11/70\n",
      "84/84 - 8s - 99ms/step - accuracy: 0.8582 - loss: 0.3612 - val_accuracy: 0.7902 - val_loss: 0.5265\n",
      "Epoch 12/70\n",
      "84/84 - 8s - 99ms/step - accuracy: 0.8587 - loss: 0.3510 - val_accuracy: 0.7902 - val_loss: 0.5355\n",
      "Epoch 13/70\n",
      "84/84 - 8s - 98ms/step - accuracy: 0.8632 - loss: 0.3478 - val_accuracy: 0.7723 - val_loss: 0.5868\n",
      "Epoch 14/70\n",
      "84/84 - 8s - 98ms/step - accuracy: 0.8703 - loss: 0.3325 - val_accuracy: 0.7857 - val_loss: 0.5645\n",
      "Epoch 15/70\n",
      "84/84 - 8s - 99ms/step - accuracy: 0.8880 - loss: 0.3008 - val_accuracy: 0.7946 - val_loss: 0.5319\n",
      "Epoch 16/70\n",
      "84/84 - 8s - 98ms/step - accuracy: 0.8926 - loss: 0.2770 - val_accuracy: 0.7887 - val_loss: 0.5387\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 183ms/step - accuracy: 0.8004 - loss: 0.4976\n",
      "DenseNet121 - Test accuracy: 0.8208\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 265ms/step\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92       192\n",
      "           1       0.81      0.87      0.84       158\n",
      "           2       0.90      0.96      0.93       161\n",
      "           3       0.90      0.86      0.88       149\n",
      "           4       0.89      0.88      0.89       170\n",
      "           5       0.89      0.83      0.86       164\n",
      "           6       0.72      0.83      0.77       181\n",
      "           7       0.81      0.68      0.74       184\n",
      "           8       0.77      0.59      0.67       169\n",
      "           9       0.64      0.80      0.71       152\n",
      "\n",
      "    accuracy                           0.82      1680\n",
      "   macro avg       0.82      0.82      0.82      1680\n",
      "weighted avg       0.83      0.82      0.82      1680\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VGG16\n",
      "Epoch 1/70\n",
      "84/84 - 23s - 276ms/step - accuracy: 0.2351 - loss: 2.2552 - val_accuracy: 0.3393 - val_loss: 1.7465\n",
      "Epoch 2/70\n",
      "84/84 - 15s - 180ms/step - accuracy: 0.3449 - loss: 1.7301 - val_accuracy: 0.4174 - val_loss: 1.5530\n",
      "Epoch 3/70\n",
      "84/84 - 15s - 182ms/step - accuracy: 0.4029 - loss: 1.5623 - val_accuracy: 0.4814 - val_loss: 1.4065\n",
      "Epoch 4/70\n",
      "84/84 - 15s - 183ms/step - accuracy: 0.4524 - loss: 1.4200 - val_accuracy: 0.5208 - val_loss: 1.2818\n",
      "Epoch 5/70\n",
      "84/84 - 16s - 185ms/step - accuracy: 0.4724 - loss: 1.3442 - val_accuracy: 0.5201 - val_loss: 1.2368\n",
      "Epoch 6/70\n",
      "84/84 - 15s - 184ms/step - accuracy: 0.4930 - loss: 1.2770 - val_accuracy: 0.5469 - val_loss: 1.2146\n",
      "Epoch 7/70\n",
      "84/84 - 15s - 183ms/step - accuracy: 0.5152 - loss: 1.2249 - val_accuracy: 0.5439 - val_loss: 1.1586\n",
      "Epoch 8/70\n",
      "84/84 - 15s - 183ms/step - accuracy: 0.5332 - loss: 1.1850 - val_accuracy: 0.5826 - val_loss: 1.1122\n",
      "Epoch 9/70\n",
      "84/84 - 15s - 182ms/step - accuracy: 0.5554 - loss: 1.1506 - val_accuracy: 0.5952 - val_loss: 1.0718\n",
      "Epoch 10/70\n",
      "84/84 - 15s - 182ms/step - accuracy: 0.5634 - loss: 1.1029 - val_accuracy: 0.6071 - val_loss: 1.0744\n",
      "Epoch 11/70\n",
      "84/84 - 15s - 183ms/step - accuracy: 0.5798 - loss: 1.0675 - val_accuracy: 0.6086 - val_loss: 1.0343\n",
      "Epoch 12/70\n",
      "84/84 - 15s - 183ms/step - accuracy: 0.5913 - loss: 1.0350 - val_accuracy: 0.6079 - val_loss: 1.0043\n",
      "Epoch 13/70\n",
      "84/84 - 15s - 183ms/step - accuracy: 0.6121 - loss: 1.0088 - val_accuracy: 0.6190 - val_loss: 0.9946\n",
      "Epoch 14/70\n",
      "84/84 - 15s - 183ms/step - accuracy: 0.6086 - loss: 0.9904 - val_accuracy: 0.6354 - val_loss: 0.9691\n",
      "Epoch 15/70\n",
      "84/84 - 15s - 182ms/step - accuracy: 0.6289 - loss: 0.9800 - val_accuracy: 0.6406 - val_loss: 0.9814\n",
      "Epoch 16/70\n",
      "84/84 - 15s - 182ms/step - accuracy: 0.6291 - loss: 0.9551 - val_accuracy: 0.6101 - val_loss: 0.9908\n",
      "Epoch 17/70\n",
      "84/84 - 15s - 183ms/step - accuracy: 0.6529 - loss: 0.9231 - val_accuracy: 0.6443 - val_loss: 0.9606\n",
      "Epoch 18/70\n",
      "84/84 - 15s - 183ms/step - accuracy: 0.6460 - loss: 0.9122 - val_accuracy: 0.6585 - val_loss: 0.9267\n",
      "Epoch 19/70\n",
      "84/84 - 15s - 183ms/step - accuracy: 0.6544 - loss: 0.8951 - val_accuracy: 0.6503 - val_loss: 0.9203\n",
      "Epoch 20/70\n",
      "84/84 - 15s - 182ms/step - accuracy: 0.6616 - loss: 0.8767 - val_accuracy: 0.6503 - val_loss: 0.9290\n",
      "Epoch 21/70\n",
      "84/84 - 15s - 183ms/step - accuracy: 0.6665 - loss: 0.8681 - val_accuracy: 0.6682 - val_loss: 0.8911\n",
      "Epoch 22/70\n",
      "84/84 - 15s - 182ms/step - accuracy: 0.6840 - loss: 0.8306 - val_accuracy: 0.6414 - val_loss: 0.9440\n",
      "Epoch 23/70\n",
      "84/84 - 15s - 182ms/step - accuracy: 0.6853 - loss: 0.8203 - val_accuracy: 0.6682 - val_loss: 0.9048\n",
      "Epoch 24/70\n",
      "84/84 - 15s - 182ms/step - accuracy: 0.6873 - loss: 0.8002 - val_accuracy: 0.6615 - val_loss: 0.9022\n",
      "Epoch 25/70\n",
      "84/84 - 15s - 183ms/step - accuracy: 0.7007 - loss: 0.7977 - val_accuracy: 0.6585 - val_loss: 0.9025\n",
      "Epoch 26/70\n",
      "84/84 - 15s - 182ms/step - accuracy: 0.7069 - loss: 0.7809 - val_accuracy: 0.6667 - val_loss: 0.9047\n",
      "Epoch 27/70\n",
      "84/84 - 15s - 184ms/step - accuracy: 0.7050 - loss: 0.7902 - val_accuracy: 0.6689 - val_loss: 0.8814\n",
      "Epoch 28/70\n",
      "84/84 - 15s - 183ms/step - accuracy: 0.7097 - loss: 0.7579 - val_accuracy: 0.6704 - val_loss: 0.8986\n",
      "Epoch 29/70\n",
      "84/84 - 15s - 183ms/step - accuracy: 0.7160 - loss: 0.7449 - val_accuracy: 0.6689 - val_loss: 0.8846\n",
      "Epoch 30/70\n",
      "84/84 - 15s - 182ms/step - accuracy: 0.7197 - loss: 0.7438 - val_accuracy: 0.6548 - val_loss: 0.9253\n",
      "Epoch 31/70\n",
      "84/84 - 15s - 183ms/step - accuracy: 0.7218 - loss: 0.7304 - val_accuracy: 0.6667 - val_loss: 0.8972\n",
      "Epoch 32/70\n",
      "84/84 - 15s - 183ms/step - accuracy: 0.7279 - loss: 0.7113 - val_accuracy: 0.6637 - val_loss: 0.8979\n",
      "Epoch 33/70\n",
      "84/84 - 15s - 184ms/step - accuracy: 0.7292 - loss: 0.6955 - val_accuracy: 0.6696 - val_loss: 0.8791\n",
      "Epoch 34/70\n",
      "84/84 - 15s - 184ms/step - accuracy: 0.7324 - loss: 0.7050 - val_accuracy: 0.6771 - val_loss: 0.8646\n",
      "Epoch 35/70\n",
      "84/84 - 15s - 183ms/step - accuracy: 0.7311 - loss: 0.6934 - val_accuracy: 0.6682 - val_loss: 0.8854\n",
      "Epoch 36/70\n",
      "84/84 - 15s - 183ms/step - accuracy: 0.7495 - loss: 0.6770 - val_accuracy: 0.6592 - val_loss: 0.9246\n",
      "Epoch 37/70\n",
      "84/84 - 15s - 182ms/step - accuracy: 0.7499 - loss: 0.6604 - val_accuracy: 0.6652 - val_loss: 0.9172\n",
      "Epoch 38/70\n",
      "84/84 - 15s - 183ms/step - accuracy: 0.7460 - loss: 0.6705 - val_accuracy: 0.6689 - val_loss: 0.9245\n",
      "Epoch 39/70\n",
      "84/84 - 15s - 182ms/step - accuracy: 0.7508 - loss: 0.6508 - val_accuracy: 0.6682 - val_loss: 0.9204\n",
      "Epoch 40/70\n",
      "84/84 - 15s - 183ms/step - accuracy: 0.7560 - loss: 0.6352 - val_accuracy: 0.6652 - val_loss: 0.9185\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - accuracy: 0.6572 - loss: 0.8477\n",
      "VGG16 - Test accuracy: 0.6792\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.80      0.83       192\n",
      "           1       0.71      0.63      0.67       158\n",
      "           2       0.80      0.85      0.83       161\n",
      "           3       0.61      0.80      0.69       149\n",
      "           4       0.67      0.79      0.72       170\n",
      "           5       0.62      0.55      0.58       164\n",
      "           6       0.72      0.70      0.71       181\n",
      "           7       0.72      0.69      0.70       184\n",
      "           8       0.47      0.56      0.51       169\n",
      "           9       0.65      0.39      0.49       152\n",
      "\n",
      "    accuracy                           0.68      1680\n",
      "   macro avg       0.68      0.68      0.67      1680\n",
      "weighted avg       0.68      0.68      0.68      1680\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Model  Test Accuracy  Training Time (s)\n",
      "0  InceptionV3       0.755952         104.221189\n",
      "1     Xception       0.776786         150.843951\n",
      "2    MobileNet       0.771429          60.885965\n",
      "3  MobileNetV2       0.786905          77.086972\n",
      "4  DenseNet121       0.820833         188.740318\n",
      "5        VGG16       0.679167         627.622063\n"
     ]
    }
   ],
   "source": [
    "cnn_sim_combined(X_img_train, X_img_test, X_meta_train, X_meta_test, y_train_enc, y_test_enc, \"meta\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pf7OV0h6Aezd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 155409,
     "status": "ok",
     "timestamp": 1749159355490,
     "user": {
      "displayName": "Aleksandra Hendrysiak",
      "userId": "02783590481816071264"
     },
     "user_tz": -120
    },
    "id": "pf7OV0h6Aezd",
    "outputId": "128bd78b-5848-4607-ef8a-215fa3e31581"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 70ms/step - accuracy: 0.1386 - loss: 2.7881 - val_accuracy: 0.2999 - val_loss: 1.9366\n",
      "Epoch 2/70\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - accuracy: 0.2496 - loss: 2.0178 - val_accuracy: 0.3705 - val_loss: 1.6708\n",
      "Epoch 3/70\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - accuracy: 0.3341 - loss: 1.7765 - val_accuracy: 0.3735 - val_loss: 1.6031\n",
      "Epoch 4/70\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - accuracy: 0.3542 - loss: 1.6903 - val_accuracy: 0.3914 - val_loss: 1.5563\n",
      "Epoch 5/70\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - accuracy: 0.3762 - loss: 1.6228 - val_accuracy: 0.4152 - val_loss: 1.4805\n",
      "Epoch 6/70\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - accuracy: 0.3914 - loss: 1.5410 - val_accuracy: 0.4561 - val_loss: 1.4620\n",
      "Epoch 7/70\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - accuracy: 0.4321 - loss: 1.4899 - val_accuracy: 0.4747 - val_loss: 1.3672\n",
      "Epoch 8/70\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - accuracy: 0.4639 - loss: 1.4179 - val_accuracy: 0.5060 - val_loss: 1.2902\n",
      "Epoch 9/70\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - accuracy: 0.5007 - loss: 1.3242 - val_accuracy: 0.5260 - val_loss: 1.2771\n",
      "Epoch 10/70\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - accuracy: 0.5065 - loss: 1.2689 - val_accuracy: 0.5365 - val_loss: 1.2069\n",
      "Epoch 11/70\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - accuracy: 0.5501 - loss: 1.2070 - val_accuracy: 0.5536 - val_loss: 1.1662\n",
      "Epoch 12/70\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - accuracy: 0.5701 - loss: 1.1211 - val_accuracy: 0.5223 - val_loss: 1.2446\n",
      "Epoch 13/70\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - accuracy: 0.5763 - loss: 1.0767 - val_accuracy: 0.5565 - val_loss: 1.1790\n",
      "Epoch 14/70\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - accuracy: 0.6179 - loss: 0.9743 - val_accuracy: 0.5677 - val_loss: 1.1425\n",
      "Epoch 15/70\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - accuracy: 0.6308 - loss: 0.9193 - val_accuracy: 0.5521 - val_loss: 1.1976\n",
      "Epoch 16/70\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - accuracy: 0.6487 - loss: 0.8804 - val_accuracy: 0.5439 - val_loss: 1.2172\n",
      "Epoch 17/70\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - accuracy: 0.6885 - loss: 0.7917 - val_accuracy: 0.5632 - val_loss: 1.1917\n",
      "Epoch 18/70\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - accuracy: 0.7192 - loss: 0.7363 - val_accuracy: 0.5662 - val_loss: 1.2391\n",
      "Epoch 19/70\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - accuracy: 0.7406 - loss: 0.6783 - val_accuracy: 0.5848 - val_loss: 1.2912\n",
      "Epoch 20/70\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - accuracy: 0.7558 - loss: 0.6431 - val_accuracy: 0.5900 - val_loss: 1.2517\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Concatenate\n",
    "\n",
    "def combined_cnn_model(image_shape=(224, 224, 3), meta_shape=(10,), num_classes=10):\n",
    "    image_input = Input(shape=image_shape, name=\"image_input\")\n",
    "    x = Conv2D(32, (3, 3), activation='relu')(image_input)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    meta_input = Input(shape=meta_shape, name=\"meta_input\")\n",
    "    m = Dense(64, activation='relu')(meta_input)\n",
    "    m = Dropout(0.3)(m)\n",
    "\n",
    "    combined = Concatenate()([x, m])\n",
    "    combined = Dense(128, activation='relu')(combined)\n",
    "    combined = Dropout(0.5)(combined)\n",
    "    output = Dense(num_classes, activation='softmax')(combined)\n",
    "\n",
    "    model = Model(inputs=[image_input, meta_input], outputs=output)\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "model = combined_cnn_model(image_shape=X_img_train.shape[1:], meta_shape=X_meta_train.shape[1:], num_classes=len(le.classes_))\n",
    "\n",
    "history = model.fit(\n",
    "    [X_img_train, X_meta_train], y_train_enc,\n",
    "    epochs=70,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "y_prob = model.predict([X_img_test, X_meta_test])\n",
    "y_pred = np.argmax(y_prob, axis=1)\n",
    "y_true = np.argmax(y_test_enc, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-cHZ3BvWA-pD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4690,
     "status": "ok",
     "timestamp": 1749159470039,
     "user": {
      "displayName": "Aleksandra Hendrysiak",
      "userId": "02783590481816071264"
     },
     "user_tz": -120
    },
    "id": "-cHZ3BvWA-pD",
    "outputId": "dab54d3d-6c80-44d2-ffaa-09eb66e320f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.5904 - loss: 1.0868\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.77      0.82       192\n",
      "           1       0.46      0.74      0.57       158\n",
      "           2       0.81      0.88      0.84       161\n",
      "           3       0.68      0.60      0.64       149\n",
      "           4       0.83      0.69      0.76       170\n",
      "           5       0.48      0.56      0.52       164\n",
      "           6       0.64      0.26      0.37       181\n",
      "           7       0.54      0.71      0.61       184\n",
      "           8       0.44      0.45      0.45       169\n",
      "           9       0.49      0.43      0.46       152\n",
      "\n",
      "    accuracy                           0.61      1680\n",
      "   macro avg       0.63      0.61      0.60      1680\n",
      "weighted avg       0.63      0.61      0.61      1680\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "param = \"meta\"\n",
    "name = \"my\"\n",
    "loss, acc = model.evaluate([X_img_test, X_meta_test], y_test_enc)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "with open(f\"/content/drive/MyDrive/Master - A/3_fig/{param}_{name}_results.txt\", \"w\") as f:\n",
    "    f.write(f\"Model: {name}\\n\")\n",
    "    #f.write(f\"Training time: {training_time:.2f} sec\\n\")\n",
    "    f.write(f\"Accuracy: {acc:.4f}\\n\\n\")\n",
    "    f.write(\"Classification Report:\\n\")\n",
    "    f.write(classification_report(y_true, y_pred))\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"/content/drive/MyDrive/Master - A/3_fig/{param}_{name}_matrix.png\")\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"/content/drive/MyDrive/Master - A/3_fig/{param}_{name}_train_val_loss.png\")\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"/content/drive/MyDrive/Master - A/3_fig/{param}_{name}_train_val_accuracy.png\")\n",
    "plt.close()\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_true, y_prob[:, 1]) if y_prob.shape[1] == 2 else (None, None, None)\n",
    "if fpr is not None:\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})', lw=2)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"/content/drive/MyDrive/Master - A/3_fig/{param}_{name}_roc_curve.png\")\n",
    "    plt.close()\n",
    "\n",
    "model.save(f'/content/drive/MyDrive/Master - A/3_fig/{param}_{name}_model.h5')\n",
    "\n",
    "results.append({\n",
    "    'Model': name,\n",
    "    'Test Accuracy': acc,\n",
    "    'Training Time (s)': training_time\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6Ubjbe-yB_Ng",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 75,
     "status": "ok",
     "timestamp": 1749159526590,
     "user": {
      "displayName": "Aleksandra Hendrysiak",
      "userId": "02783590481816071264"
     },
     "user_tz": -120
    },
    "id": "6Ubjbe-yB_Ng",
    "outputId": "eb30f3d3-0314-457c-da0e-0536e50db3e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Model  Test Accuracy  Training Time (s)\n",
      "0  InceptionV3       0.738690         127.865819\n",
      "1     Xception       0.760119         208.671374\n",
      "2    MobileNet       0.792857          89.317813\n",
      "3  MobileNetV2       0.794048          99.906089\n",
      "4  DenseNet121       0.818452         209.636113\n",
      "5        VGG16       0.675000         891.858847\n",
      "6           my       0.551190          91.106546\n",
      "7           my       0.610119          91.106546\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(f'/content/drive/MyDrive/Master - A/3_fig/{param}_model_training_results.csv', index=False)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7211b6",
   "metadata": {
    "id": "2b7211b6"
   },
   "source": [
    "## Klasyczne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "QF-AGuvCuV31",
   "metadata": {
    "executionInfo": {
     "elapsed": 152,
     "status": "ok",
     "timestamp": 1749214560414,
     "user": {
      "displayName": "Aleksandra Hendrysiak",
      "userId": "02783590481816071264"
     },
     "user_tz": -120
    },
    "id": "QF-AGuvCuV31"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score,confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "IBZUxmjiTtls",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1749214495861,
     "user": {
      "displayName": "Aleksandra Hendrysiak",
      "userId": "02783590481816071264"
     },
     "user_tz": -120
    },
    "id": "IBZUxmjiTtls"
   },
   "outputs": [],
   "source": [
    "X_img_train_flat = X_img_train.reshape(X_img_train.shape[0], -1)\n",
    "X_img_test_flat = X_img_test.reshape(X_img_test.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xqxDmCg_T7UI",
   "metadata": {
    "id": "xqxDmCg_T7UI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c32dda66",
   "metadata": {
    "executionInfo": {
     "elapsed": 406223,
     "status": "ok",
     "timestamp": 1749210114821,
     "user": {
      "displayName": "Aleksandra Hendrysiak",
      "userId": "02783590481816071264"
     },
     "user_tz": -120
    },
    "id": "c32dda66"
   },
   "outputs": [],
   "source": [
    "X_img_train_flat = X_img_train.reshape(X_img_train.shape[0], -1)\n",
    "X_img_test_flat = X_img_test.reshape(X_img_test.shape[0], -1)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2000)\n",
    "X_train_pca = pca.fit_transform(X_img_train_flat)\n",
    "X_test_pca = pca.transform(X_img_test_flat)\n",
    "X_train_combined = np.concatenate([X_train_pca, X_meta_train], axis=1)\n",
    "X_test_combined = np.concatenate([X_test_pca, X_meta_test], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jxwCyObSywUF",
   "metadata": {
    "id": "jxwCyObSywUF"
   },
   "outputs": [],
   "source": [
    "del X_meta_train, X_meta_test,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "WRCK9fzHmZwj",
   "metadata": {
    "executionInfo": {
     "elapsed": 508,
     "status": "ok",
     "timestamp": 1749214557516,
     "user": {
      "displayName": "Aleksandra Hendrysiak",
      "userId": "02783590481816071264"
     },
     "user_tz": -120
    },
    "id": "WRCK9fzHmZwj"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5DqE4qb_0zH1",
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1749214572773,
     "user": {
      "displayName": "Aleksandra Hendrysiak",
      "userId": "02783590481816071264"
     },
     "user_tz": -120
    },
    "id": "5DqE4qb_0zH1"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Sve6_vq8dZ0p",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 983554,
     "status": "ok",
     "timestamp": 1749205871996,
     "user": {
      "displayName": "Aleksandra Hendrysiak",
      "userId": "02783590481816071264"
     },
     "user_tz": -120
    },
    "id": "Sve6_vq8dZ0p",
    "outputId": "222c8370-50de-40ea-e990-db17d84e70a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LogisticRegression_D - training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Results:\n",
      "LogisticRegression_D: 0.3696\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import gc\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, classification_report, confusion_matrix, roc_curve, auc\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "model_classes = [\n",
    "    ('LogisticRegression_D', LogisticRegression(multi_class='multinomial', max_iter=5000)),\n",
    "    #('NaiveBayes_D', GaussianNB())\n",
    "]\n",
    "\n",
    "results = []\n",
    "param = \"meta22\"\n",
    "\n",
    "y_train_labels = np.argmax(y_train_enc, axis=1)\n",
    "y_test_labels = np.argmax(y_test_enc, axis=1)\n",
    "\n",
    "for name, model in model_classes:\n",
    "    print(f\"\\n{name} - training...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    model.fit(X_train_combined, y_train_labels)\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "\n",
    "    y_pred = model.predict(X_test_combined)\n",
    "\n",
    "    try:\n",
    "        y_prob = model.predict_proba(X_test_combined)\n",
    "    except:\n",
    "        y_prob = None\n",
    "\n",
    "    accuracy = accuracy_score(y_test_labels, y_pred)\n",
    "    report = classification_report(y_test_labels, y_pred)\n",
    "\n",
    "    with open(f\"/content/drive/MyDrive/Master - A/3_fig/{param}_{name}_results.txt\", \"w\") as f:\n",
    "        f.write(f\"Model: {name}\\n\")\n",
    "        f.write(f\"Training time: {training_time:.2f} sec\\n\")\n",
    "        f.write(f\"Accuracy: {accuracy:.4f}\\n\\n\")\n",
    "        f.write(\"Classification Report:\\n\")\n",
    "        f.write(report)\n",
    "\n",
    "    conf_matrix = confusion_matrix(y_test_labels, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"/content/drive/MyDrive/Master - A/3_fig/{param}_{name}_matrix.png\")\n",
    "    plt.close()\n",
    "\n",
    "    if y_prob is not None and y_prob.shape[1] == 2:\n",
    "        fpr, tpr, _ = roc_curve(y_test_labels, y_prob[:, 1])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})', lw=2)\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title(\"ROC Curve\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"/content/drive/MyDrive/Master - A/3_fig/{param}_{name}_roc_curve.png\")\n",
    "        plt.close()\n",
    "\n",
    "    results.append((name, accuracy))\n",
    "\n",
    "    del model, y_pred\n",
    "    gc.collect()\n",
    "\n",
    "with open(f\"/content/drive/MyDrive/Master - A/3_fig/{param}_final_results.csv\", mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Model\", \"Accuracy\"])\n",
    "    for name, acc in results:\n",
    "        writer.writerow([name, f\"{acc:.4f}\"])\n",
    "\n",
    "print(\"\\nFinal Results:\")\n",
    "for name, acc in results:\n",
    "    print(f\"{name}: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8exLYMvAcY7h",
   "metadata": {
    "executionInfo": {
     "elapsed": 7101,
     "status": "ok",
     "timestamp": 1749282430470,
     "user": {
      "displayName": "Aleksandra Hendrysiak",
      "userId": "02783590481816071264"
     },
     "user_tz": -120
    },
    "id": "8exLYMvAcY7h"
   },
   "outputs": [],
   "source": [
    "col_means = np.nanmean(X_meta_test, axis=0)\n",
    "inds = np.where(np.isnan(X_meta_test))\n",
    "X_meta_test[inds] = np.take(col_means, inds[1])\n",
    "\n",
    "col_means = np.nanmean(X_meta_train, axis=0)\n",
    "inds = np.where(np.isnan(X_meta_train))\n",
    "X_meta_train[inds] = np.take(col_means, inds[1])\n",
    "\n",
    "X_img_train_flat = X_img_train.reshape(X_img_train.shape[0], -1)\n",
    "X_img_test_flat = X_img_test.reshape(X_img_test.shape[0], -1)\n",
    "X_train_combined = np.concatenate([X_img_train_flat, X_meta_train], axis=1)\n",
    "X_test_combined = np.concatenate([X_img_test_flat, X_meta_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7rQ1tZN7c_Lx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1749216976916,
     "user": {
      "displayName": "Aleksandra Hendrysiak",
      "userId": "02783590481816071264"
     },
     "user_tz": -120
    },
    "id": "7rQ1tZN7c_Lx",
    "outputId": "f9bec64b-d30d-4a8d-9334-b59a519ad137"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6717, 150533), (1680, 150533))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_combined.shape, X_test_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82l1lz6fd69J",
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1749282387873,
     "user": {
      "displayName": "Aleksandra Hendrysiak",
      "userId": "02783590481816071264"
     },
     "user_tz": -120
    },
    "id": "82l1lz6fd69J"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "col_means = np.nanmean(X_meta_test, axis=0)\n",
    "inds = np.where(np.isnan(X_meta_test))\n",
    "X_meta_test[inds] = np.take(col_means, inds[1])\n",
    "\n",
    "col_means = np.nanmean(X_meta_train, axis=0)\n",
    "inds = np.where(np.isnan(X_meta_train))\n",
    "X_meta_train[inds] = np.take(col_means, inds[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Rrah2RUvmMZi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2153295,
     "status": "ok",
     "timestamp": 1749219321559,
     "user": {
      "displayName": "Aleksandra Hendrysiak",
      "userId": "02783590481816071264"
     },
     "user_tz": -120
    },
    "id": "Rrah2RUvmMZi",
    "outputId": "8f9e90af-1ea2-41b0-8219-cee924c712d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KNN_D - training...\n",
      "\n",
      "DecisionTree_D - training...\n",
      "\n",
      "RandomForest_D - training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Results:\n",
      "KNN_D: 0.1875\n",
      "DecisionTree_D: 0.3333\n",
      "RandomForest_D: 0.1345\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "model_classes = [\n",
    "    ('KNN_D', KNeighborsClassifier()),\n",
    "    ('DecisionTree_D', DecisionTreeClassifier()),\n",
    "    ('RandomForest_D', RandomForestClassifier()),\n",
    "    #('LogisticRegression_D', LogisticRegression()),\n",
    "    #('NaiveBayes_D', GaussianNB())\n",
    "]\n",
    "\n",
    "results = []\n",
    "param = \"5_meta\"\n",
    "\n",
    "for name, model in model_classes:\n",
    "    print(f\"\\n{name} - training...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    model.fit(X_train_combined, y_train_enc)\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "\n",
    "    preds = model.predict(X_test_combined)\n",
    "    acc_preview = accuracy_score(y_test_enc, preds)\n",
    "\n",
    "    y_prob = model.predict(X_test_combined)\n",
    "    y_pred = np.argmax(y_prob, axis=1)\n",
    "    #y_pred = y_prob\n",
    "    y_true = np.argmax(y_test_enc, axis=1)\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    report = classification_report(y_true, y_pred)\n",
    "\n",
    "    with open(f\"/content/drive/MyDrive/Master - A/3_fig/{param}_{name}_results.txt\", \"w\") as f:\n",
    "        f.write(f\"Model: {name}\\n\")\n",
    "        f.write(f\"Training time: {training_time:.2f} sec\\n\")\n",
    "        f.write(f\"Accuracy: {accuracy:.4f}\\n\\n\")\n",
    "        f.write(\"Classification Report:\\n\")\n",
    "        f.write(report)\n",
    "\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"/content/drive/MyDrive/Master - A/3_fig/{param}_{name}_matrix.png\")\n",
    "    plt.close()\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_prob[:, 1]) if y_prob.shape[1] == 2 else (None, None, None)\n",
    "    if fpr is not None:\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})', lw=2)\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"/content/drive/MyDrive/Master - A/3_fig/{param}_{name}_roc_curve.png\")\n",
    "        plt.close()\n",
    "\n",
    "    results.append((name, accuracy))\n",
    "\n",
    "    del model, preds\n",
    "    gc.collect()\n",
    "\n",
    "with open(f\"/content/drive/MyDrive/Master - A/3_fig/{param}_final_results.csv\", mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Model\", \"Accuracy\"])\n",
    "    for name, acc in results:\n",
    "        writer.writerow([name, f\"{acc:.4f}\"])\n",
    "\n",
    "print(\"\\nFinal Results:\")\n",
    "for name, acc in results:\n",
    "    print(f\"{name}: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XCfgHGr8Snhl",
   "metadata": {
    "id": "XCfgHGr8Snhl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TP68L2fs1olh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "executionInfo": {
     "elapsed": 831,
     "status": "error",
     "timestamp": 1749211694703,
     "user": {
      "displayName": "Aleksandra Hendrysiak",
      "userId": "02783590481816071264"
     },
     "user_tz": -120
    },
    "id": "TP68L2fs1olh",
    "outputId": "8bb14434-fdcf-42ac-b480-7055019ef23f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KNN_D - training...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [6717, 1680]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-ba2d509bb42e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_prob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_enc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0macc_preview\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattach_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \"\"\"\n\u001b[1;32m     97\u001b[0m     \u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_namespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_pred\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [6717, 1680]"
     ]
    }
   ],
   "source": [
    "model_classes = [\n",
    "    ('KNN_D', KNeighborsClassifier()),\n",
    "    ('DecisionTree_D', DecisionTreeClassifier()),\n",
    "     ('RandomForest_D', RandomForestClassifier()),\n",
    "    #('LogisticRegression_D', LogisticRegression(multi_class='multinomial')),\n",
    "    #('NaiveBayes_D', GaussianNB())\n",
    "]\n",
    "\n",
    "results = []\n",
    "param = \"pca_meta2\"\n",
    "\n",
    "for name, model in model_classes:\n",
    "    print(f\"\\n{name} - training...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    y_train_labels = np.argmax(y_train_enc, axis=1)\n",
    "    y_test_labels = np.argmax(y_train_enc, axis=1)\n",
    "    model.fit(X_train_combined, y_train_labels)\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "\n",
    "    preds = model.predict(X_test_combined)\n",
    "\n",
    "    y_prob = model.predict(X_test_combined)\n",
    "    y_pred = y_prob\n",
    "    y_true = np.argmax(y_test_enc, axis=1)\n",
    "    acc_preview = accuracy_score(y_test_labels, y_pred)\n",
    "\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    report = classification_report(y_true, y_pred)\n",
    "\n",
    "    with open(f\"/content/drive/MyDrive/Master - A/3_fig/{param}_{name}_results.txt\", \"w\") as f:\n",
    "        f.write(f\"Model: {name}\\n\")\n",
    "        f.write(f\"Training time: {training_time:.2f} sec\\n\")\n",
    "        f.write(f\"Accuracy: {accuracy:.4f}\\n\\n\")\n",
    "        f.write(\"Classification Report:\\n\")\n",
    "        f.write(report)\n",
    "\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"/content/drive/MyDrive/Master - A/3_fig/{param}_{name}_matrix.png\")\n",
    "    plt.close()\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_prob[:, 1]) if y_prob.shape[1] == 2 else (None, None, None)\n",
    "    if fpr is not None:\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})', lw=2)\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"/content/drive/MyDrive/Master - A/3_fig/{param}_{name}_roc_curve.png\")\n",
    "        plt.close()\n",
    "\n",
    "    results.append((name, accuracy))\n",
    "\n",
    "    del model, preds\n",
    "    gc.collect()\n",
    "\n",
    "with open(f\"/content/drive/MyDrive/Master - A/3_fig/{param}_final_results.csv\", mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Model\", \"Accuracy\"])\n",
    "    for name, acc in results:\n",
    "        writer.writerow([name, f\"{acc:.4f}\"])\n",
    "\n",
    "print(\"\\nFinal Results:\")\n",
    "for name, acc in results:\n",
    "    print(f\"{name}: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0hUUt1mwe--s",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5092759,
     "status": "ok",
     "timestamp": 1749229797360,
     "user": {
      "displayName": "Aleksandra Hendrysiak",
      "userId": "02783590481816071264"
     },
     "user_tz": -120
    },
    "id": "0hUUt1mwe--s",
    "outputId": "477cc2d3-8f1e-460a-c4ae-2abd99abc18d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LogisticRegression_D - training...\n",
      "1749222058.6759188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NaiveBayes_D - training...\n",
      "1749229691.2187786\n",
      "\n",
      "Final Results:\n",
      "LogisticRegression_D: 0.3851\n",
      "NaiveBayes_D: 0.3095\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_classes = [\n",
    "    ('LogisticRegression_D', LogisticRegression(multi_class='multinomial', max_iter=5000)),\n",
    "    ('NaiveBayes_D', GaussianNB())\n",
    "]\n",
    "\n",
    "results = []\n",
    "param = \"55_z_meta22\"\n",
    "\n",
    "y_train_labels = np.argmax(y_train_enc, axis=1)\n",
    "y_test_labels = np.argmax(y_test_enc, axis=1)\n",
    "\n",
    "for name, model in model_classes:\n",
    "    print(f\"\\n{name} - training...\")\n",
    "    start_time = time.time()\n",
    "    print(start_time)\n",
    "    model.fit(X_train_combined, y_train_labels)\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "\n",
    "    y_pred = model.predict(X_test_combined)\n",
    "\n",
    "    try:\n",
    "        y_prob = model.predict_proba(X_train_combined)\n",
    "    except:\n",
    "        y_prob = None\n",
    "\n",
    "    accuracy = accuracy_score(y_test_labels, y_pred)\n",
    "    report = classification_report(y_test_labels, y_pred)\n",
    "\n",
    "    with open(f\"/content/drive/MyDrive/Master - A/3_fig/{param}_{name}_results.txt\", \"w\") as f:\n",
    "        f.write(f\"Model: {name}\\n\")\n",
    "        f.write(f\"Training time: {training_time:.2f} sec\\n\")\n",
    "        f.write(f\"Accuracy: {accuracy:.4f}\\n\\n\")\n",
    "        f.write(\"Classification Report:\\n\")\n",
    "        f.write(report)\n",
    "\n",
    "    conf_matrix = confusion_matrix(y_test_labels, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"/content/drive/MyDrive/Master - A/3_fig/{param}_{name}_matrix.png\")\n",
    "    plt.close()\n",
    "\n",
    "    if y_prob is not None and y_prob.shape[1] == 2:\n",
    "        fpr, tpr, _ = roc_curve(y_test_labels, y_prob[:, 1])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})', lw=2)\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title(\"ROC Curve\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"/content/drive/MyDrive/Master - A/3_fig/{param}_{name}_roc_curve.png\")\n",
    "        plt.close()\n",
    "\n",
    "    results.append((name, accuracy))\n",
    "\n",
    "    del model, y_pred\n",
    "    gc.collect()\n",
    "\n",
    "with open(f\"/content/drive/MyDrive/Master - A/3_fig/{param}_final_results.csv\", mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Model\", \"Accuracy\"])\n",
    "    for name, acc in results:\n",
    "        writer.writerow([name, f\"{acc:.4f}\"])\n",
    "\n",
    "print(\"\\nFinal Results:\")\n",
    "for name, acc in results:\n",
    "    print(f\"{name}: {acc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
