{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ILpBzgcCiV7J"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "random.seed(42)\n",
    "from sklearn.metrics import classification_report, accuracy_score,confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from tensorflow.keras.models import load_model\n",
    "import gc\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 59848,
     "status": "ok",
     "timestamp": 1749285183111,
     "user": {
      "displayName": "Aleksandra Hendrysiak",
      "userId": "02783590481816071264"
     },
     "user_tz": -120
    },
    "id": "69LOYGQV2MaF",
    "outputId": "143d5aa5-ce7e-429d-ab77-dbfe3cd207ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "15wTw7nT2cse"
   },
   "outputs": [],
   "source": [
    "with open(\"/content/drive/MyDrive/Master - A/june_muchomor_sromotnikowy_12500.pkl\", \"rb\") as f:\n",
    "    X_muchomor = pickle.load(f)\n",
    "with open(\"/content/drive/MyDrive/Master - A/june_kania_12500.pkl\", \"rb\") as f:\n",
    "    X_kania = pickle.load(f)\n",
    "\n",
    "labels_muchomory = list(np.zeros(len(X_muchomor)))\n",
    "labels_kania = list(np.ones(len((X_kania))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dQfuIMVu2tor"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "X = np.array(X_kania + X_muchomor)\n",
    "y = np.array(labels_kania + labels_muchomory)\n",
    "X = X.reshape(-1, 224, 224, 3).astype('float32')\n",
    "X = X.reshape(X.shape[0], -1)\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X = scaler.fit_transform(X)\n",
    "\n",
    "# pca = PCA(n_components=2000)\n",
    "# X = pca.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "del X, y, X_muchomor, labels_muchomory, X_kania, labels_kania\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "38-srNlo47nB"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ParameterGrid, cross_val_score\n",
    "\n",
    "model_classes = [\n",
    "    ('KNN', KNeighborsClassifier(), {\n",
    "        'n_neighbors': list(range(3, 21)),\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'p': [1, 2]\n",
    "    }),\n",
    "\n",
    "    ('DecisionTree', DecisionTreeClassifier(), {\n",
    "        'max_depth': [None, 5, 10, 15, 20],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 5],\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_features': [None, 'sqrt', 'log2']\n",
    "    }),\n",
    "\n",
    "    ('RandomForest', RandomForestClassifier(), {\n",
    "        'n_estimators': [10, 25, 50, 100, 150, 200],\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'max_features': ['sqrt', 'log2', None]\n",
    "    }),\n",
    "\n",
    "    ('Logistic regression', LogisticRegression(), {\n",
    "        'penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "        'C': [0.01, 0.1, 0.5, 1, 10, 100],\n",
    "        'solver': ['liblinear', 'saga', 'lbfgs', 'newton-cg'],\n",
    "        'max_iter': [50, 100, 150, 200, 250, 300, 250, 400, 450, 500]\n",
    "    })\n",
    "    ,\n",
    "\n",
    "    ('AdaBoost', AdaBoostClassifier(), {\n",
    "        'n_estimators': [50, 75, 100, 125, 150, 175, 200],\n",
    "        'learning_rate': [0.01, 0.05, 0.1, 1.0]\n",
    "    }),\n",
    "\n",
    "    ('NaiveBayes', GaussianNB(), {\n",
    "    })\n",
    "]\n",
    "\n",
    "def sim_grid(X_train, X_test, y_train, y_test, param=None):\n",
    "    if param==None:\n",
    "        param = \"\"\n",
    "\n",
    "    results = []\n",
    "    best = []\n",
    "\n",
    "    for name, model, param_grid in model_classes:\n",
    "        print(f\"{name} - tuning...\")\n",
    "\n",
    "        grid = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "        start_time = time.time()\n",
    "\n",
    "        grid.fit(X_train, y_train)\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        best_model = grid.best_estimator_\n",
    "        joblib.dump(best_model, f\"models/{param}_{name}_best_model.pkl\")\n",
    "        preds = best_model.predict(X_test)\n",
    "        acc = accuracy_score(y_test, preds)\n",
    "        with open(f\"/content/drive/MyDrive/Master - A/2_fig/{param}_{name}_results.txt\", \"w\") as f:\n",
    "          f.write(f\"Model: {name}\\n\")\n",
    "          f.write(f\"Training time: {elapsed_time:.2f} sec\\n\")\n",
    "          f.write(f\"Accuracy: {acc:.4f}\\n\\n\")\n",
    "          f.write(\"Classification Report:\\n\")\n",
    "\n",
    "        #print(f\"{name} - Best Params: {grid.best_params_}\")\n",
    "        #print(f\"{name} - Test Accuracy: {acc:.4f}\")\n",
    "        #print(f\"Training time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "\n",
    "\n",
    "        #print(classification_report(y_test, preds))\n",
    "\n",
    "        conf_matrix = confusion_matrix(y_test, preds)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"E\", \"P\"], yticklabels=[\"E\", \"P\"])\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.savefig(f\"/content/drive/MyDrive/Master - A/2_fig/{param}_{name}_matrix.png\")\n",
    "        plt.close()\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_test, preds)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        plt.xlabel('False Positive Rate', fontsize=18)\n",
    "        plt.ylabel('True Positive Rate', fontsize=18)\n",
    "        plt.xticks(fontsize=18)\n",
    "        plt.yticks(fontsize=18)\n",
    "        plt.legend(loc=\"lower right\", fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"/content/drive/MyDrive/Master - A/2_fig/{param}_{name}_roc_curve.png\")\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "        results.append((name, acc))\n",
    "        best.append((name, grid.best_params_))\n",
    "\n",
    "        results_df = pd.DataFrame(grid.cv_results_)\n",
    "        results_df = pd.DataFrame(grid.cv_results_)\n",
    "        param_cols = [col for col in results_df.columns if col.startswith('param_')]\n",
    "        results_df = results_df[param_cols + ['mean_test_score', 'mean_fit_time', 'rank_test_score']]\n",
    "        results_df.to_csv(f\"/content/drive/MyDrive/Master - A/2_fig{param}_{name}.csv\")\n",
    "\n",
    "    for name, acc in results:\n",
    "        print(f\"{name}: {acc:.4f}\")\n",
    "\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333
    },
    "executionInfo": {
     "elapsed": 5147841,
     "status": "error",
     "timestamp": 1749131780220,
     "user": {
      "displayName": "Aleksandra Hendrysiak",
      "userId": "02783590481816071264"
     },
     "user_tz": -120
    },
    "id": "0G_RvPPdDT7x",
    "outputId": "df2fb4ea-cd4f-43ff-decb-55cb170e3e24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN - tuning...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-dc6bb14cf23f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msim_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-33ca2eadecb8>\u001b[0m in \u001b[0;36msim_grid\u001b[0;34m(X_train, X_test, y_train, y_test, param)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1022\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1569\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1570\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1571\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    968\u001b[0m                     )\n\u001b[1;32m    969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    971\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    972\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         )\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2070\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2072\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2074\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1681\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1682\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1798\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTASK_PENDING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1799\u001b[0m                 ):\n\u001b[0;32m-> 1800\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1801\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sim_grid(X_train[:5000], X_test, y_train[:5000], y_test, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vleTeQby6cOj"
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qnP898qIiBoh"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc\n",
    "import csv\n",
    "\n",
    "model_classes = [\n",
    "    ('KNN_D', KNeighborsClassifier()),\n",
    "    ('DecisionTree_D', DecisionTreeClassifier()),\n",
    "    ('RandomForest_D', RandomForestClassifier()),\n",
    "    ('LogisticRegression_D', LogisticRegression())\n",
    "]\n",
    "\n",
    "param_grid = {\n",
    "    'KNN_D': [{'n_neighbors': k} for k in [11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]],\n",
    "    'DecisionTree_D': [{'max_depth': d} for d in [5, 10, 15, 20, 25, 30, None]],\n",
    "    'RandomForest_D': [{'n_estimators': n, 'max_depth': d, 'max_features': 'sqrt'} for n in [50, 100, 1000] for d in [10, 20]],\n",
    "}\n",
    "\n",
    "def classical_sim(X_train, X_test, y_train, y_test, param=120):\n",
    "    results = []\n",
    "\n",
    "    for name, model in model_classes:\n",
    "        print(f\"\\n{name} - training...\")\n",
    "\n",
    "        for param_set in param_grid.get(name, []):\n",
    "            print(f\"Testing with parameters: {param_set}\")\n",
    "\n",
    "            start_time = time.time()\n",
    "\n",
    "            model.set_params(**param_set)\n",
    "\n",
    "            model.fit(X_train, y_train)\n",
    "            end_time = time.time()\n",
    "            training_time = end_time - start_time\n",
    "\n",
    "            preds = model.predict(X_test)\n",
    "            accuracy = accuracy_score(y_test, preds)\n",
    "            report = classification_report(y_test, preds)\n",
    "\n",
    "            with open(f\"/content/drive/MyDrive/Master - A/2_fig/{param}_{name}_params_{param_set}_results.txt\", \"w\") as f:\n",
    "                f.write(f\"Model: {name}\\n\")\n",
    "                f.write(f\"Parameters: {param_set}\\n\")\n",
    "                f.write(f\"Training time: {training_time:.2f} sec\\n\")\n",
    "                f.write(f\"Accuracy: {accuracy:.4f}\\n\\n\")\n",
    "                f.write(\"Classification Report:\\n\")\n",
    "                f.write(report)\n",
    "\n",
    "            conf_matrix = confusion_matrix(y_test, preds)\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "            plt.title(f\"{name} - Confusion Matrix\")\n",
    "            plt.xlabel(\"Predicted\")\n",
    "            plt.ylabel(\"Actual\")\n",
    "            plt.savefig(f\"/content/drive/MyDrive/Master - A/2_fig/{param}_{name}_params_{param_set}_matrix.png\")\n",
    "            plt.close()\n",
    "\n",
    "            fpr, tpr, _ = roc_curve(y_test, preds)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "            plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "            plt.xlabel('False Positive Rate', fontsize=18)\n",
    "            plt.ylabel('True Positive Rate', fontsize=18)\n",
    "            plt.xticks(fontsize=18)\n",
    "            plt.yticks(fontsize=18)\n",
    "            plt.legend(loc=\"lower right\", fontsize=14)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"/content/drive/MyDrive/Master - A/2_fig/{param}_{name}_params_{param_set}_roc_curve.png\")\n",
    "            plt.close()\n",
    "\n",
    "            results.append((name, param_set, accuracy))\n",
    "\n",
    "\n",
    "    with open(f\"/content/drive/MyDrive/Master - A/2_fig/{param}_final_results.csv\", mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Model\", \"Parameters\", \"Accuracy\"])\n",
    "        for name, param_set, acc in results:\n",
    "            writer.writerow([name, str(param_set), f\"{acc:.4f}\"])\n",
    "\n",
    "    print(\"\\nFinal Results:\")\n",
    "    for name, param_set, acc in results:\n",
    "        print(f\"{name} with parameters {param_set}: {acc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21509461,
     "status": "ok",
     "timestamp": 1749312556165,
     "user": {
      "displayName": "Aleksandra Hendrysiak",
      "userId": "02783590481816071264"
     },
     "user_tz": -120
    },
    "id": "XPIT-KSgiEIf",
    "outputId": "47c3b1a9-6408-4280-d2ca-c1e242ab166a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KNN_D - training...\n",
      "Testing with parameters: {'n_neighbors': 11}\n",
      "Testing with parameters: {'n_neighbors': 12}\n",
      "Testing with parameters: {'n_neighbors': 13}\n",
      "Testing with parameters: {'n_neighbors': 14}\n",
      "Testing with parameters: {'n_neighbors': 15}\n",
      "Testing with parameters: {'n_neighbors': 16}\n",
      "Testing with parameters: {'n_neighbors': 17}\n",
      "Testing with parameters: {'n_neighbors': 18}\n",
      "Testing with parameters: {'n_neighbors': 19}\n",
      "Testing with parameters: {'n_neighbors': 20}\n",
      "Testing with parameters: {'n_neighbors': 21}\n",
      "Testing with parameters: {'n_neighbors': 22}\n",
      "Testing with parameters: {'n_neighbors': 23}\n",
      "Testing with parameters: {'n_neighbors': 24}\n",
      "Testing with parameters: {'n_neighbors': 25}\n",
      "\n",
      "DecisionTree_D - training...\n",
      "Testing with parameters: {'max_depth': 5}\n",
      "Testing with parameters: {'max_depth': 10}\n",
      "Testing with parameters: {'max_depth': 15}\n",
      "Testing with parameters: {'max_depth': 20}\n",
      "Testing with parameters: {'max_depth': 25}\n",
      "Testing with parameters: {'max_depth': 30}\n",
      "Testing with parameters: {'max_depth': None}\n",
      "\n",
      "RandomForest_D - training...\n",
      "Testing with parameters: {'n_estimators': 50, 'max_depth': 10, 'max_features': 'sqrt'}\n",
      "Testing with parameters: {'n_estimators': 50, 'max_depth': 20, 'max_features': 'sqrt'}\n",
      "Testing with parameters: {'n_estimators': 100, 'max_depth': 10, 'max_features': 'sqrt'}\n",
      "Testing with parameters: {'n_estimators': 100, 'max_depth': 20, 'max_features': 'sqrt'}\n",
      "Testing with parameters: {'n_estimators': 1000, 'max_depth': 10, 'max_features': 'sqrt'}\n",
      "Testing with parameters: {'n_estimators': 1000, 'max_depth': 20, 'max_features': 'sqrt'}\n",
      "\n",
      "LogisticRegression_D - training...\n",
      "\n",
      "Final Results:\n",
      "KNN_D with parameters {'n_neighbors': 11}: 0.5407\n",
      "KNN_D with parameters {'n_neighbors': 12}: 0.5525\n",
      "KNN_D with parameters {'n_neighbors': 13}: 0.5365\n",
      "KNN_D with parameters {'n_neighbors': 14}: 0.5425\n",
      "KNN_D with parameters {'n_neighbors': 15}: 0.5365\n",
      "KNN_D with parameters {'n_neighbors': 16}: 0.5393\n",
      "KNN_D with parameters {'n_neighbors': 17}: 0.5337\n",
      "KNN_D with parameters {'n_neighbors': 18}: 0.5411\n",
      "KNN_D with parameters {'n_neighbors': 19}: 0.5339\n",
      "KNN_D with parameters {'n_neighbors': 20}: 0.5387\n",
      "KNN_D with parameters {'n_neighbors': 21}: 0.5359\n",
      "KNN_D with parameters {'n_neighbors': 22}: 0.5415\n",
      "KNN_D with parameters {'n_neighbors': 23}: 0.5331\n",
      "KNN_D with parameters {'n_neighbors': 24}: 0.5347\n",
      "KNN_D with parameters {'n_neighbors': 25}: 0.5313\n",
      "DecisionTree_D with parameters {'max_depth': 5}: 0.6362\n",
      "DecisionTree_D with parameters {'max_depth': 10}: 0.6250\n",
      "DecisionTree_D with parameters {'max_depth': 15}: 0.6256\n",
      "DecisionTree_D with parameters {'max_depth': 20}: 0.6150\n",
      "DecisionTree_D with parameters {'max_depth': 25}: 0.6116\n",
      "DecisionTree_D with parameters {'max_depth': 30}: 0.6134\n",
      "DecisionTree_D with parameters {'max_depth': None}: 0.6070\n",
      "RandomForest_D with parameters {'n_estimators': 50, 'max_depth': 10, 'max_features': 'sqrt'}: 0.7158\n",
      "RandomForest_D with parameters {'n_estimators': 50, 'max_depth': 20, 'max_features': 'sqrt'}: 0.7164\n",
      "RandomForest_D with parameters {'n_estimators': 100, 'max_depth': 10, 'max_features': 'sqrt'}: 0.7242\n",
      "RandomForest_D with parameters {'n_estimators': 100, 'max_depth': 20, 'max_features': 'sqrt'}: 0.7346\n",
      "RandomForest_D with parameters {'n_estimators': 1000, 'max_depth': 10, 'max_features': 'sqrt'}: 0.7356\n",
      "RandomForest_D with parameters {'n_estimators': 1000, 'max_depth': 20, 'max_features': 'sqrt'}: 0.7482\n"
     ]
    }
   ],
   "source": [
    "classical_sim(X_train[:12000], X_test, y_train[:12000], y_test, param = \"june_12\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "executionInfo": {
     "elapsed": 5826863,
     "status": "error",
     "timestamp": 1749318418498,
     "user": {
      "displayName": "Aleksandra Hendrysiak",
      "userId": "02783590481816071264"
     },
     "user_tz": -120
    },
    "id": "Ee_SttGaiRAw",
    "outputId": "c5e824ff-6095-4d38-95bd-d57e46f31630"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KNN_D - training...\n",
      "Testing with parameters: {'n_neighbors': 11}\n",
      "Testing with parameters: {'n_neighbors': 12}\n",
      "Testing with parameters: {'n_neighbors': 13}\n",
      "Testing with parameters: {'n_neighbors': 14}\n",
      "Testing with parameters: {'n_neighbors': 15}\n",
      "Testing with parameters: {'n_neighbors': 16}\n",
      "Testing with parameters: {'n_neighbors': 17}\n",
      "Testing with parameters: {'n_neighbors': 18}\n",
      "Testing with parameters: {'n_neighbors': 19}\n",
      "Testing with parameters: {'n_neighbors': 20}\n",
      "Testing with parameters: {'n_neighbors': 21}\n",
      "Testing with parameters: {'n_neighbors': 22}\n",
      "Testing with parameters: {'n_neighbors': 23}\n",
      "Testing with parameters: {'n_neighbors': 24}\n",
      "Testing with parameters: {'n_neighbors': 25}\n",
      "\n",
      "DecisionTree_D - training...\n",
      "Testing with parameters: {'max_depth': 5}\n",
      "Testing with parameters: {'max_depth': 10}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-49c0865f03c5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclassical_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m16000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m16000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"june_16\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-8388765ee9d2>\u001b[0m in \u001b[0;36mclassical_sim\u001b[0;34m(X_train, X_test, y_train, y_test, param)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;31m# Trenowanie modelu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mtraining_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \"\"\"\n\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m         super()._fit(\n\u001b[0m\u001b[1;32m   1025\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    470\u001b[0m             )\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing_values_in_feature_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "classical_sim(X_train[:16000], X_test, y_train[:16000], y_test, param = \"june_16\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "38EFFLLCdEol"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D9WorvrbiVfm"
   },
   "outputs": [],
   "source": [
    "classical_sim(X_train, X_test, y_train, y_test, param = \"june_20\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lR1DaN0t02fi"
   },
   "outputs": [],
   "source": [
    "model_classes = [\n",
    "    ('KNN_D', KNeighborsClassifier()),\n",
    "    ('DecisionTree_D', DecisionTreeClassifier()),\n",
    "    ('RandomForest_D', RandomForestClassifier()),\n",
    "    #('AdaBoost_D', AdaBoostClassifier()),\n",
    "    ('LogisticRegression_D', LogisticRegression()),\n",
    "]\n",
    "\n",
    "def classical_sim(X_train, X_test, y_train, y_test, param=120):\n",
    "    results = []\n",
    "\n",
    "    for name, model in model_classes:\n",
    "        print(f\"\\n{name} - training...\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        end_time = time.time()\n",
    "        training_time = end_time - start_time\n",
    "\n",
    "        preds = model.predict(X_test)\n",
    "        acc_preview = accuracy_score(y_test, preds)\n",
    "\n",
    "        y_prob = model.predict(X_test)\n",
    "        y_pred = (y_prob > 0.5).astype(\"int32\")\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        report = classification_report(y_test, y_pred)\n",
    "\n",
    "        with open(f\"/content/drive/MyDrive/Master - A/2_fig/{param}_{name}_results.txt\", \"w\") as f:\n",
    "            f.write(f\"Model: {name}\\n\")\n",
    "            f.write(f\"Training time: {training_time:.2f} sec\\n\")\n",
    "            f.write(f\"Accuracy: {accuracy:.4f}\\n\\n\")\n",
    "            f.write(\"Classification Report:\\n\")\n",
    "            f.write(report)\n",
    "\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.savefig(f\"/content/drive/MyDrive/Master - A/2_fig/{param}_{name}_matrix.png\")\n",
    "        plt.close()\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        plt.xlabel('False Positive Rate', fontsize=18)\n",
    "        plt.ylabel('True Positive Rate', fontsize=18)\n",
    "        plt.xticks(fontsize=18)\n",
    "        plt.yticks(fontsize=18)\n",
    "        plt.legend(loc=\"lower right\", fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"/content/drive/MyDrive/Master - A/2_fig/{param}_{name}_roc_curve.png\")\n",
    "        plt.close()\n",
    "\n",
    "        results.append((name, accuracy))\n",
    "\n",
    "        del model, preds\n",
    "        gc.collect()\n",
    "\n",
    "    with open(f\"/content/drive/MyDrive/Master - A/2_fig/{param}_final_results.csv\", mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Model\", \"Accuracy\"])\n",
    "        for name, acc in results:\n",
    "            writer.writerow([name, f\"{acc:.4f}\"])\n",
    "\n",
    "    print(\"\\nFinal Results:\")\n",
    "    for name, acc in results:\n",
    "        print(f\"{name}: {acc:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1749123998925,
     "user": {
      "displayName": "Aleksandra Hendrysiak",
      "userId": "02783590481816071264"
     },
     "user_tz": -120
    },
    "id": "5SfH6RBdrZ2O",
    "outputId": "6ce84046-8a7c-42e2-e2ab-f3e2bd5f2b75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19986,)\n",
      "(4997,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TGxBEQyD735f"
   },
   "source": [
    "# 6000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 497
    },
    "executionInfo": {
     "elapsed": 13584620,
     "status": "error",
     "timestamp": 1749145508173,
     "user": {
      "displayName": "Aleksandra Hendrysiak",
      "userId": "02783590481816071264"
     },
     "user_tz": -120
    },
    "id": "DLU4Ogu473lF",
    "outputId": "edf82c60-7572-4cca-f5ab-5ee2a5918de2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KNN_D - training...\n",
      "\n",
      "DecisionTree_D - training...\n",
      "\n",
      "RandomForest_D - training...\n",
      "\n",
      "AdaBoost_D - training...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-38f2349ea5e0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclassical_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m12000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m12000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m112000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-5a7aba8ab4bb>\u001b[0m in \u001b[0;36mclassical_sim\u001b[0;34m(X_train, X_test, y_train, y_test, param)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mtraining_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0;31m# Boosting step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m             sample_weight, estimator_weight, estimator_error = self._boost(\n\u001b[0m\u001b[1;32m    168\u001b[0m                 \u001b[0miboost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             )\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36m_boost\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0my_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \"\"\"\n\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m         super()._fit(\n\u001b[0m\u001b[1;32m   1025\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    470\u001b[0m             )\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing_values_in_feature_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import csv\n",
    "classical_sim(X_train[:12000], X_test, y_train[:12000], y_test, 112000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s-HTu9DC745M"
   },
   "source": [
    "#8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7368007,
     "status": "ok",
     "timestamp": 1749152891153,
     "user": {
      "displayName": "Aleksandra Hendrysiak",
      "userId": "02783590481816071264"
     },
     "user_tz": -120
    },
    "id": "uvgF9hNW74uz",
    "outputId": "cd30122e-7e48-4805-a40e-b1e6098b767a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KNN_D - training...\n",
      "\n",
      "DecisionTree_D - training...\n",
      "\n",
      "RandomForest_D - training...\n",
      "\n",
      "LogisticRegression_D - training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Results:\n",
      "KNN_D: 0.5549\n",
      "DecisionTree_D: 0.6166\n",
      "RandomForest_D: 0.7400\n",
      "LogisticRegression_D: 0.6956\n"
     ]
    }
   ],
   "source": [
    "classical_sim(X_train[:16000], X_test, y_train[:16000], y_test, 16000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HvanE_3X75MF"
   },
   "source": [
    "### 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9005401,
     "status": "ok",
     "timestamp": 1749161896562,
     "user": {
      "displayName": "Aleksandra Hendrysiak",
      "userId": "02783590481816071264"
     },
     "user_tz": -120
    },
    "id": "qD2F_Qmt75UV",
    "outputId": "a12fbb30-8cf7-4f37-dcf3-5fecb106e701"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KNN_D - training...\n",
      "\n",
      "DecisionTree_D - training...\n",
      "\n",
      "RandomForest_D - training...\n",
      "\n",
      "LogisticRegression_D - training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Results:\n",
      "KNN_D: 0.5523\n",
      "DecisionTree_D: 0.6302\n",
      "RandomForest_D: 0.7410\n",
      "LogisticRegression_D: 0.7106\n"
     ]
    }
   ],
   "source": [
    "classical_sim(X_train, X_test, y_train, y_test, 20000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 151738,
     "status": "ok",
     "timestamp": 1749162048991,
     "user": {
      "displayName": "Aleksandra Hendrysiak",
      "userId": "02783590481816071264"
     },
     "user_tz": -120
    },
    "id": "e5pt_5yHEqqA",
    "outputId": "60b4b3f4-19dd-4cbf-cc43-3614cf519da0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LogisticRegression_D - training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NaiveBayes_D - training...\n",
      "\n",
      "Final Results:\n",
      "LogisticRegression_D: 0.6808\n",
      "NaiveBayes_D: 0.6450\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "model_classes = [\n",
    "    #('KNN_D', KNeighborsClassifier()),\n",
    "    #('DecisionTree_D', DecisionTreeClassifier()),\n",
    "    #('RandomForest_D', RandomForestClassifier()),\n",
    "    #('AdaBoost_D', AdaBoostClassifier()),\n",
    "    ('LogisticRegression_D', LogisticRegression()),\n",
    "    ('NaiveBayes_D', GaussianNB())\n",
    "]\n",
    "classical_sim(X_train[:12000], X_test, y_train[:12000], y_test, 112000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 107939,
     "status": "ok",
     "timestamp": 1749163427225,
     "user": {
      "displayName": "Aleksandra Hendrysiak",
      "userId": "02783590481816071264"
     },
     "user_tz": -120
    },
    "id": "2dk0MYtKQgz-",
    "outputId": "58c3ccdc-088e-489f-efdf-1657f25248d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NaiveBayes_D - training...\n",
      "\n",
      "Final Results:\n",
      "NaiveBayes_D: 0.6458\n",
      "\n",
      "NaiveBayes_D - training...\n",
      "\n",
      "Final Results:\n",
      "NaiveBayes_D: 0.6432\n"
     ]
    }
   ],
   "source": [
    "model_classes = [\n",
    "    ('NaiveBayes_D', GaussianNB())\n",
    "]\n",
    "\n",
    "classical_sim(X_train[:16000], X_test, y_train[:16000], y_test, 16000)\n",
    "classical_sim(X_train, X_test, y_train, y_test, 20000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "MjiLXgsGRS0A",
    "outputId": "84152497-f602-45db-8ab9-395b687ce7cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVM_D - training...\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "model_classes = [\n",
    "    ('SVM_D', SVC()),\n",
    "]\n",
    "classical_sim(X_train[:12000], X_test, y_train[:12000], y_test, 1112000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PDvCQys1SIPD"
   },
   "outputs": [],
   "source": [
    "classical_sim(X_train[:16000], X_test, y_train[:16000], y_test, 16000)\n",
    "classical_sim(X_train, X_test, y_train, y_test, 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "riJuEbFL0rGl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HGmtfMMv1JoY"
   },
   "source": [
    "# GRID SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WtuR9jwQ1OLm"
   },
   "outputs": [],
   "source": [
    "X_train_new, X_val, y_train_new, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.1, random_state=42, stratify=y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tRL9vOZS1pOW"
   },
   "outputs": [],
   "source": [
    "del X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oXruL6Up0rTP"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import gc\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, classification_report,\n",
    "    confusion_matrix, roc_curve, auc\n",
    ")\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "def classical_sim_grid(X_val, y_val, X_train, X_test, y_train, y_test, param=\"grid\"):\n",
    "    results = []\n",
    "\n",
    "    model_classes = {\n",
    "        'KNN_D': (KNeighborsClassifier(), {\n",
    "            'n_neighbors': list(range(3, 26))\n",
    "        }),\n",
    "        'DecisionTree_D': (DecisionTreeClassifier(), {\n",
    "            'max_depth': [5, 10, 15, 20, 25, 30, None]\n",
    "        }),\n",
    "        'RandomForest_D': (RandomForestClassifier(), {\n",
    "            'n_estimators': [50, 100, 1000],\n",
    "            'max_depth': [10, 20],\n",
    "            'max_features': ['sqrt']\n",
    "        }),\n",
    "       \n",
    "    }\n",
    "\n",
    "    for name, (model, param_grid) in model_classes.items():\n",
    "        print(f\"\\n{name} - Grid Search...\")\n",
    "\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=model,\n",
    "            param_grid=param_grid,\n",
    "            scoring='accuracy',\n",
    "            cv=3,\n",
    "            n_jobs=-1,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        start_time = time.time()\n",
    "        grid_search.fit(X_val, y_val)\n",
    "        training_time = time.time() - start_time\n",
    "\n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_params = grid_search.best_params_\n",
    "        print(f\"Best params: {best_params}\")\n",
    "\n",
    "        start_time = time.time()\n",
    "        model.set_params(**best_params)\n",
    "        model.fit(X_train, y_train)\n",
    "        end_time = time.time()\n",
    "        training_time = end_time - start_time\n",
    "\n",
    "        preds = model.predict(X_test)\n",
    "        acc_preview = accuracy_score(y_test, preds)\n",
    "\n",
    "        y_prob = model.predict(X_test)\n",
    "        y_pred = y_prob\n",
    "        y_true = y_test\n",
    "\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        report = classification_report(y_true, y_pred)\n",
    "\n",
    "        filename_prefix = f\"/content/drive/MyDrive/Master - A/2_fig/{param}_{name}\"\n",
    "        with open(f\"{filename_prefix}_results.txt\", \"w\") as f:\n",
    "            f.write(f\"Model: {name}\\n\")\n",
    "            f.write(f\"Best Parameters: {best_params}\\n\")\n",
    "            f.write(f\"Training time: {training_time:.2f} sec\\n\")\n",
    "            f.write(f\"Accuracy: {accuracy:.4f}\\n\\n\")\n",
    "            f.write(\"Classification Report:\\n\")\n",
    "            f.write(report)\n",
    "\n",
    "        conf_matrix = confusion_matrix(y_test, preds)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "        plt.title(f\"{name} - Confusion Matrix\")\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{filename_prefix}_matrix.png\")\n",
    "        plt.close()\n",
    "\n",
    "        try:\n",
    "            if len(np.unique(y_test)) == 2:\n",
    "                y_score = best_model.predict_proba(X_test)[:, 1]\n",
    "                fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "                roc_auc = auc(fpr, tpr)\n",
    "\n",
    "                plt.figure(figsize=(8, 6))\n",
    "                plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC (AUC = {roc_auc:.2f})')\n",
    "                plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "                plt.xlabel('False Positive Rate')\n",
    "                plt.ylabel('True Positive Rate')\n",
    "                plt.title('ROC Curve')\n",
    "                plt.legend(loc=\"lower right\")\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f\"{filename_prefix}_roc_curve.png\")\n",
    "                plt.close()\n",
    "        except Exception as e:\n",
    "            print(f\" ROC failed: {e}\")\n",
    "\n",
    "        results.append((name, best_params, accuracy))\n",
    "\n",
    "        del grid_search, best_model, preds, conf_matrix\n",
    "        gc.collect()\n",
    "\n",
    "    with open(f\"/content/drive/MyDrive/Master - A/2_fig/{param}_final_results.csv\", mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Model\", \"Best Parameters\", \"Accuracy\"])\n",
    "        for name, best_params, acc in results:\n",
    "            writer.writerow([name, str(best_params), f\"{acc:.4f}\"])\n",
    "\n",
    "    print(\"\\nFinal Results:\")\n",
    "    for name, best_params, acc in results:\n",
    "        print(f\"{name} with best parameters {best_params}: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9932658,
     "status": "ok",
     "timestamp": 1749338193278,
     "user": {
      "displayName": "Aleksandra Hendrysiak",
      "userId": "02783590481816071264"
     },
     "user_tz": -120
    },
    "id": "n8o1nYE62TZe",
    "outputId": "e412c573-1a3c-487f-c899-fec3fd03730f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KNN_D - Grid Search...\n",
      "Fitting 3 folds for each of 23 candidates, totalling 69 fits\n",
      "Best params: {'n_neighbors': 4}\n",
      "\n",
      "DecisionTree_D - Grid Search...\n",
      "Fitting 3 folds for each of 7 candidates, totalling 21 fits\n",
      "Best params: {'max_depth': 25}\n",
      "\n",
      "RandomForest_D - Grid Search...\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "Best params: {'max_depth': 20, 'max_features': 'sqrt', 'n_estimators': 1000}\n",
      "\n",
      "Final Results:\n",
      "KNN_D with best parameters {'n_neighbors': 4}: 0.5725\n",
      "DecisionTree_D with best parameters {'max_depth': 25}: 0.6314\n",
      "RandomForest_D with best parameters {'max_depth': 20, 'max_features': 'sqrt', 'n_estimators': 1000}: 0.7541\n"
     ]
    }
   ],
   "source": [
    "classical_sim_grid(X_val, y_val, X_train_new, X_test, y_train_new, y_test, param = \"_classical_grid_juneeee\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN4xMxGLkGRmadUPKlgGJ9k",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
